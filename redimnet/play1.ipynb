{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test files\n",
    " * espeak \"Hello, this is a test.\" -w test00.wav\n",
    " * espeak \"this is the same voice\" -w test01.wav\n",
    "\n",
    " * test2.wav - something random from the internet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /data/deep/redimnet/models/IDRnD_ReDimNet_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/deep/redimnet/models/IDRnD_ReDimNet_master\n",
      "load_res : <All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ReDimNetWrap(\n",
       "  (backbone): ReDimNet(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): LayerNorm(C=(24,), data_format=channels_first, eps=1e-06)\n",
       "      (2): to1d()\n",
       "    )\n",
       "    (stage0): Sequential(\n",
       "      (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=24)\n",
       "      (2): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv1pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv2pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv1pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv2pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv1pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv2pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv1pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
       "          (conv2pw): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3)\n",
       "        (1): BatchNorm2d(24, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (8): to1d()\n",
       "      (9): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1728, 72, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(72,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(7,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(19,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(31,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(59,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (v_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (q_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (out_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(72, 1728, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): weigth1d(w=(1, 2, 1728, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=24)\n",
       "      (2): Conv2d(24, 96, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (7): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (8): Sequential(\n",
       "        (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=6)\n",
       "        (1): BatchNorm2d(48, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (9): to1d()\n",
       "      (10): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1728, 72, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(72,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(7,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(19,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(31,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(59,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (v_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (q_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (out_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(72, 1728, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): weigth1d(w=(1, 3, 1728, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=48)\n",
       "      (2): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (7): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (8): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (9): Sequential(\n",
       "        (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=6)\n",
       "        (1): BatchNorm2d(48, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (10): to1d()\n",
       "      (11): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1728, 72, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(72,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(7,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(19,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(31,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(59,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (v_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (q_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (out_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(72, 1728, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): weigth1d(w=(1, 4, 1728, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=48)\n",
       "      (2): Conv2d(48, 96, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (7): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (8): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (9): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (10): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (11): to1d()\n",
       "      (12): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1728, 72, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(72,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(7,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(19,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(31,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(59,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (v_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (q_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (out_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(72, 1728, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): weigth1d(w=(1, 5, 1728, 1),sequential=False)\n",
       "      (1): to2d(f=18,c=96)\n",
       "      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (7): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (8): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (9): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (10): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv1pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
       "          (conv2pw): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (11): to1d()\n",
       "      (12): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1728, 72, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(72,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(7,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(19,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(31,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(59,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (v_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (q_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (out_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(72, 1728, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage5): Sequential(\n",
       "      (0): weigth1d(w=(1, 6, 1728, 1),sequential=False)\n",
       "      (1): to2d(f=18,c=96)\n",
       "      (2): Conv2d(96, 192, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (conv1pw): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (conv2pw): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (conv1pw): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (conv2pw): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (conv1pw): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (conv2pw): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): to1d()\n",
       "      (7): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1728, 72, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(72,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(7,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(19,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(31,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(72, 72, kernel_size=(59,), stride=(1,), padding=same, groups=72)\n",
       "            )\n",
       "            (norm): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(72, 72, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (v_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (q_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (out_proj): Linear(in_features=72, out_features=72, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=72, out_features=72, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((72,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(72, 1728, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (fin_wght1d): weigth1d(w=(1, 7, 1728, 1),sequential=False)\n",
       "    (mfa): Identity()\n",
       "    (fin_to2d): Identity()\n",
       "  )\n",
       "  (spec): MelBanks(\n",
       "    (torchfbank): Sequential(\n",
       "      (0): NormalizeAudio()\n",
       "      (1): PreEmphasis()\n",
       "      (2): MelSpectrogram(\n",
       "        (spectrogram): Spectrogram()\n",
       "        (mel_scale): MelScale()\n",
       "      )\n",
       "    )\n",
       "    (specaug): FbankAug()\n",
       "  )\n",
       "  (pool): ASTP(\n",
       "    (linear1): Conv1d(5184, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1728, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(3456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=3456, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name='M' # ~b3-b4 size\n",
    "train_type='ft_mix'\n",
    "dataset='vb2+vox2+cnc'\n",
    "\n",
    "torch.hub.set_dir('/data/deep/redimnet/models')\n",
    "\n",
    "model = torch.hub.load('IDRnD/ReDimNet', 'ReDimNet', \n",
    "                       model_name=model_name, \n",
    "                       train_type=train_type, \n",
    "                       dataset=dataset)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speaker_embedding(wav_path, target_sample_rate=16000, target_length=32000):\n",
    "    \"\"\"\n",
    "    Extracts a speaker embedding from a given WAV file using the ReDimNet model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The ReDimNet model\n",
    "    - wav_path: Path to the WAV file\n",
    "    - target_sample_rate: Sample rate the model expects (default: 16kHz)\n",
    "    - target_length: Number of samples the model expects (default: 32000 = 2 sec @ 16kHz)\n",
    "    \n",
    "    Returns:\n",
    "    - speaker_embedding: The extracted speaker embedding as a PyTorch tensor\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    \n",
    "    # Convert to mono if needed\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # Resample if needed\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    # Ensure the waveform has exactly `target_length` samples\n",
    "    if waveform.shape[1] < target_length:\n",
    "        # Pad with zeros if too short\n",
    "        pad_size = target_length - waveform.shape[1]\n",
    "        waveform = F.pad(waveform, (0, pad_size))\n",
    "    else:\n",
    "        # Trim if too long\n",
    "        waveform = waveform[:, :target_length]\n",
    "    \n",
    "    # Ensure correct shape (batch_size, num_samples)\n",
    "    print(f\"waveform Sample Shape: {waveform.shape} ; type : {type(waveform)}\")\n",
    "    \n",
    "    # Extract speaker embedding\n",
    "    with torch.no_grad():\n",
    "        speaker_embedding = model(waveform)\n",
    "        \n",
    "    print(f\"Speaker Embedding Shape: {speaker_embedding.shape} ; type : {type(speaker_embedding)}\")  # Expected: (1, embedding_dim)\n",
    "    \n",
    "    return speaker_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity between two embeddings\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1, embedding2).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/deep/redimnet/models/IDRnD_ReDimNet_master/redimnet/layers/features.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed1 = extract_speaker_embedding(wav_path='test00.wav')\n",
    "embed2 = extract_speaker_embedding(wav_path='test01.wav')\n",
    "embed3 = extract_speaker_embedding(wav_path='test2.wav')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8862158060073853\n",
      "Similarity: 0.17124216258525848\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity: {cosine_similarity(embed1, embed2)}\")\n",
    "print(f\"Similarity: {cosine_similarity(embed1, embed3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ReDimNetWrap                                                 [1, 192]                  --\n",
       "├─MelBanks: 1-1                                              [1, 72, 201]              --\n",
       "│    └─Sequential: 2-1                                       [1, 72, 201]              --\n",
       "│    │    └─NormalizeAudio: 3-1                              [1, 1, 32000]             --\n",
       "│    │    └─PreEmphasis: 3-2                                 [1, 32000]                --\n",
       "│    │    └─MelSpectrogram: 3-3                              [1, 72, 201]              --\n",
       "├─ReDimNet: 1-2                                              [1, 1728, 201]            --\n",
       "│    └─Sequential: 2-2                                       [1, 1728, 201]            --\n",
       "│    │    └─Conv2d: 3-4                                      [1, 24, 72, 201]          240\n",
       "│    │    └─LayerNorm: 3-5                                   [1, 24, 72, 201]          48\n",
       "│    │    └─to1d: 3-6                                        [1, 1728, 201]            --\n",
       "│    └─Sequential: 2-3                                       [1, 1728, 201]            --\n",
       "│    │    └─weigth1d: 3-7                                    [1, 1728, 201]            (1)\n",
       "│    │    └─to2d: 3-8                                        [1, 24, 72, 201]          --\n",
       "│    │    └─Conv2d: 3-9                                      [1, 48, 72, 201]          1,200\n",
       "│    │    └─ConvBlock2d: 3-10                                [1, 48, 72, 201]          11,808\n",
       "│    │    └─ConvBlock2d: 3-11                                [1, 48, 72, 201]          11,808\n",
       "│    │    └─ConvBlock2d: 3-12                                [1, 48, 72, 201]          11,808\n",
       "│    │    └─ConvBlock2d: 3-13                                [1, 48, 72, 201]          11,808\n",
       "│    │    └─Sequential: 3-14                                 [1, 24, 72, 201]          4,128\n",
       "│    │    └─to1d: 3-15                                       [1, 1728, 201]            --\n",
       "│    │    └─TimeContextBlock1d: 3-16                         [1, 1728, 201]            312,840\n",
       "│    └─Sequential: 2-4                                       [1, 1728, 201]            --\n",
       "│    │    └─weigth1d: 3-17                                   [1, 1728, 201]            3,456\n",
       "│    │    └─to2d: 3-18                                       [1, 24, 72, 201]          --\n",
       "│    │    └─Conv2d: 3-19                                     [1, 96, 36, 201]          4,704\n",
       "│    │    └─ConvBlock2d: 3-20                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-21                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-22                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-23                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-24                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─Sequential: 3-25                                 [1, 48, 36, 201]          9,408\n",
       "│    │    └─to1d: 3-26                                       [1, 1728, 201]            --\n",
       "│    │    └─TimeContextBlock1d: 3-27                         [1, 1728, 201]            312,840\n",
       "│    └─Sequential: 2-5                                       [1, 1728, 201]            --\n",
       "│    │    └─weigth1d: 3-28                                   [1, 1728, 201]            5,184\n",
       "│    │    └─to2d: 3-29                                       [1, 48, 36, 201]          --\n",
       "│    │    └─Conv2d: 3-30                                     [1, 96, 36, 201]          4,704\n",
       "│    │    └─ConvBlock2d: 3-31                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-32                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-33                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-34                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-35                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-36                                [1, 96, 36, 201]          32,832\n",
       "│    │    └─Sequential: 3-37                                 [1, 48, 36, 201]          9,408\n",
       "│    │    └─to1d: 3-38                                       [1, 1728, 201]            --\n",
       "│    │    └─TimeContextBlock1d: 3-39                         [1, 1728, 201]            312,840\n",
       "│    └─Sequential: 2-6                                       [1, 1728, 201]            --\n",
       "│    │    └─weigth1d: 3-40                                   [1, 1728, 201]            6,912\n",
       "│    │    └─to2d: 3-41                                       [1, 48, 36, 201]          --\n",
       "│    │    └─Conv2d: 3-42                                     [1, 96, 18, 201]          9,312\n",
       "│    │    └─ConvBlock2d: 3-43                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-44                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-45                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-46                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-47                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-48                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-49                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-50                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─to1d: 3-51                                       [1, 1728, 201]            --\n",
       "│    │    └─TimeContextBlock1d: 3-52                         [1, 1728, 201]            312,840\n",
       "│    └─Sequential: 2-7                                       [1, 1728, 201]            --\n",
       "│    │    └─weigth1d: 3-53                                   [1, 1728, 201]            8,640\n",
       "│    │    └─to2d: 3-54                                       [1, 96, 18, 201]          --\n",
       "│    │    └─Conv2d: 3-55                                     [1, 96, 18, 201]          9,312\n",
       "│    │    └─ConvBlock2d: 3-56                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-57                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-58                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-59                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-60                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-61                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-62                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─ConvBlock2d: 3-63                                [1, 96, 18, 201]          32,832\n",
       "│    │    └─to1d: 3-64                                       [1, 1728, 201]            --\n",
       "│    │    └─TimeContextBlock1d: 3-65                         [1, 1728, 201]            312,840\n",
       "│    └─Sequential: 2-8                                       [1, 1728, 201]            --\n",
       "│    │    └─weigth1d: 3-66                                   [1, 1728, 201]            10,368\n",
       "│    │    └─to2d: 3-67                                       [1, 96, 18, 201]          --\n",
       "│    │    └─Conv2d: 3-68                                     [1, 192, 9, 201]          37,056\n",
       "│    │    └─ConvBlock2d: 3-69                                [1, 192, 9, 201]          102,528\n",
       "│    │    └─ConvBlock2d: 3-70                                [1, 192, 9, 201]          102,528\n",
       "│    │    └─ConvBlock2d: 3-71                                [1, 192, 9, 201]          102,528\n",
       "│    │    └─to1d: 3-72                                       [1, 1728, 201]            --\n",
       "│    │    └─TimeContextBlock1d: 3-73                         [1, 1728, 201]            312,840\n",
       "│    └─weigth1d: 2-9                                         [1, 1728, 201]            12,096\n",
       "│    └─Identity: 2-10                                        [1, 1728, 201]            --\n",
       "│    └─Identity: 2-11                                        [1, 1728, 201]            --\n",
       "├─ASTP: 1-3                                                  [1, 3456]                 --\n",
       "│    └─Conv1d: 2-12                                          [1, 128, 201]             663,680\n",
       "│    └─Conv1d: 2-13                                          [1, 1728, 201]            222,912\n",
       "├─BatchNorm1d: 1-4                                           [1, 3456]                 6,912\n",
       "├─Linear: 1-5                                                [1, 192]                  663,744\n",
       "==============================================================================================================\n",
       "Total params: 4,811,745\n",
       "Trainable params: 4,811,744\n",
       "Non-trainable params: 1\n",
       "Total mult-adds (G): 6.62\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 926.91\n",
       "Params size (MB): 19.25\n",
       "Estimated Total Size (MB): 946.28\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 32000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:308: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch IR graph at exception: graph(%0 : Float(*, *, strides=[32000, 1], requires_grad=0, device=cpu),\n",
      "      %backbone.stem.0.weight : Float(24, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stem.0.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stem.1.weight : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stem.1.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.0.w : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.2.weight : Float(48, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.2.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.conv1.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.conv1pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.conv1pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn1.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn1.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn1.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn1.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.conv2.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.conv2pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.conv2pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn2.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn2.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn2.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn2.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.3.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.conv1.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.conv1pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.conv1pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn1.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn1.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn1.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn1.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.conv2.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.conv2pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.conv2pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn2.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn2.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn2.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn2.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.4.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.conv1.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.conv1pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.conv1pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn1.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn1.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn1.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn1.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.conv2.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.conv2pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.conv2pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn2.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn2.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn2.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn2.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.5.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.conv1.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.conv1pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.conv1pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn1.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn1.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn1.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn1.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.conv2.weight : Float(48, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.conv2pw.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.conv2pw.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn2.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn2.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn2.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn2.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.6.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.7.0.weight : Float(24, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.7.0.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.7.1.weight : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.7.1.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.7.1.running_mean : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.7.1.running_var : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.7.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.7.3.weight : Float(24, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.7.3.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.red_dim_conv.0.weight : Float(72, 1728, 1, strides=[1728, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.red_dim_conv.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.red_dim_conv.1.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.red_dim_conv.1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.dwconvs.0.weight : Float(72, 1, 7, strides=[7, 7, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.0.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.dwconvs.0.weight : Float(72, 1, 19, strides=[19, 19, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.1.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.dwconvs.0.weight : Float(72, 1, 31, strides=[31, 31, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.2.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.dwconvs.0.weight : Float(72, 1, 59, strides=[59, 59, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.3.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.k_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.k_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.v_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.v_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.q_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.q_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.out_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.attention.out_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.layer_norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.layer_norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.feed_forward.intermediate_dense.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.feed_forward.intermediate_dense.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.feed_forward.output_dense.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.feed_forward.output_dense.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.final_layer_norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.tcm.4.final_layer_norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.exp_dim_conv.weight : Float(1728, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage0.9.exp_dim_conv.bias : Float(1728, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.0.w : Float(1, 2, 1728, 1, strides=[3456, 1728, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.2.weight : Float(96, 24, 2, 1, strides=[48, 2, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.3.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.4.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.5.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.6.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.7.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.8.0.weight : Float(48, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.8.0.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.8.1.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.8.1.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.8.1.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.8.1.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.8.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.8.3.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.8.3.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.red_dim_conv.0.weight : Float(72, 1728, 1, strides=[1728, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.red_dim_conv.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.red_dim_conv.1.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.red_dim_conv.1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.dwconvs.0.weight : Float(72, 1, 7, strides=[7, 7, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.0.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.dwconvs.0.weight : Float(72, 1, 19, strides=[19, 19, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.1.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.dwconvs.0.weight : Float(72, 1, 31, strides=[31, 31, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.2.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.dwconvs.0.weight : Float(72, 1, 59, strides=[59, 59, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.3.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.k_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.k_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.v_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.v_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.q_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.q_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.out_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.attention.out_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.layer_norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.layer_norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.feed_forward.intermediate_dense.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.feed_forward.intermediate_dense.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.feed_forward.output_dense.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.feed_forward.output_dense.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.final_layer_norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.tcm.4.final_layer_norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.exp_dim_conv.weight : Float(1728, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage1.10.exp_dim_conv.bias : Float(1728, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.0.w : Float(1, 3, 1728, 1, strides=[5184, 1728, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.2.weight : Float(96, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.3.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.4.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.5.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.6.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.7.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.8.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.9.0.weight : Float(48, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.9.0.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.9.1.weight : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.9.1.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.9.1.running_mean : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.9.1.running_var : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.9.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.9.3.weight : Float(48, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.9.3.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.red_dim_conv.0.weight : Float(72, 1728, 1, strides=[1728, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.red_dim_conv.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.red_dim_conv.1.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.red_dim_conv.1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.dwconvs.0.weight : Float(72, 1, 7, strides=[7, 7, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.0.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.dwconvs.0.weight : Float(72, 1, 19, strides=[19, 19, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.1.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.dwconvs.0.weight : Float(72, 1, 31, strides=[31, 31, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.2.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.dwconvs.0.weight : Float(72, 1, 59, strides=[59, 59, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.3.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.k_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.k_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.v_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.v_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.q_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.q_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.out_proj.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.attention.out_proj.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.layer_norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.layer_norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.feed_forward.intermediate_dense.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.feed_forward.intermediate_dense.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.feed_forward.output_dense.weight : Float(72, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.feed_forward.output_dense.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.final_layer_norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.tcm.4.final_layer_norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.exp_dim_conv.weight : Float(1728, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage2.11.exp_dim_conv.bias : Float(1728, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.0.w : Float(1, 4, 1728, 1, strides=[6912, 1728, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.2.weight : Float(96, 48, 2, 1, strides=[96, 2, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.3.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.4.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.5.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.6.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.7.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.8.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.9.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.conv1.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.conv1pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.conv1pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn1.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn1.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn1.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.conv2.weight : Float(96, 8, 3, 3, strides=[72, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.conv2pw.weight : Float(96, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.conv2pw.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn2.weight : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn2.running_mean : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn2.running_var : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.10.conv_block.bn2.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.red_dim_conv.0.weight : Float(72, 1728, 1, strides=[1728, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.red_dim_conv.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.red_dim_conv.1.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.red_dim_conv.1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.dwconvs.0.weight : Float(72, 1, 7, strides=[7, 7, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.0.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.dwconvs.0.weight : Float(72, 1, 19, strides=[19, 19, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.norm.running_var : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.norm.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.pwconv1.weight : Float(72, 72, 1, strides=[72, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.1.pwconv1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.2.dwconvs.0.weight : Float(72, 1, 31, strides=[31, 31, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.2.dwconvs.0.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.2.norm.weight : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.2.norm.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.stage3.12.tcm.2.norm.running_mean : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %backbone.stage3.12.tcm.2.norm"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSymbolicValueError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py:1057\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1057\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py:632\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    630\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 632\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py:1697\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, values_in_env, new_nodes, operator_export_type)\u001b[0m\n\u001b[1;32m   1694\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1695\u001b[0m             k: symbolic_helper\u001b[38;5;241m.\u001b[39m_node_get(node, k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()\n\u001b[1;32m   1696\u001b[0m         }\n\u001b[0;32m-> 1697\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msymbolic_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1699\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1700\u001b[0m     k \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39mkindOf(k)[\u001b[38;5;241m0\u001b[39m]: symbolic_helper\u001b[38;5;241m.\u001b[39m_node_get(node, k)\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()\n\u001b[1;32m   1702\u001b[0m }\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:281\u001b[0m, in \u001b[0;36mparse_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(g, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs, (\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbolic function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m can only contain \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_outputs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFILE_BUG_MSG\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/symbolic_opset17.py:135\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(g, input, n_fft, hop_length, win_length, window, normalized, onesided, return_complex)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_complex:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mSymbolicValueError(\n\u001b[1;32m    136\u001b[0m         msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTFT does not currently support complex types\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Get STFT sizes\u001b[39;00m\n",
      "\u001b[0;31mSymbolicValueError\u001b[0m: STFT does not currently support complex types  [Caused by the value '1071 defined in (%1071 : Float(*, *, strides=[32512, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0](%1060, %1070), scope: redimnet.model.ReDimNetWrap::/redimnet.layers.features.MelBanks::spec/torch.nn.modules.container.Sequential::torchfbank/torchaudio.transforms._transforms.MelSpectrogram::torchfbank.2/torchaudio.transforms._transforms.Spectrogram::spectrogram # /data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/functional.py:708:0\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Reshape'.] \n    (node defined in /data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/functional.py(708): stft\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torchaudio/functional/functional.py(126): spectrogram\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torchaudio/transforms/_transforms.py(110): forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1729): _slow_forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1750): _call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1739): _wrapped_call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torchaudio/transforms/_transforms.py(619): forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1729): _slow_forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1750): _call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1739): _wrapped_call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/container.py(250): forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1729): _slow_forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1750): _call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1739): _wrapped_call_impl\n/data/deep/redimnet/models/IDRnD_ReDimNet_master/redimnet/layers/features.py(138): forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1729): _slow_forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1750): _call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1739): _wrapped_call_impl\n/data/deep/redimnet/models/IDRnD_ReDimNet_master/redimnet/model.py(422): forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1729): _slow_forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1750): _call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1739): _wrapped_call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/jit/_trace.py(129): wrapper\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/jit/_trace.py(138): forward\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1750): _call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/modules/module.py(1739): _wrapped_call_impl\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/jit/_trace.py(1498): _get_trace_graph\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py(844): _trace_and_get_graph_from_model\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py(937): _create_jit_graph\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py(1053): _model_to_graph\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py(1428): _export\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py(495): export\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/__init__.py(383): export\n/tmp/ipykernel_38204/312652006.py(8): <module>\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3579): run_code\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3519): run_ast_nodes\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3336): run_cell_async\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/IPython/core/async_helpers.py(128): _pseudo_sync_runner\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3132): _run_cell\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3077): run_cell\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/zmqshell.py(549): run_cell\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/ipkernel.py(449): do_execute\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py(778): execute_request\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/ipkernel.py(362): execute_request\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py(534): process_one\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n/home/vlad/mambaforge/lib/python3.10/asyncio/events.py(80): _run\n/home/vlad/mambaforge/lib/python3.10/asyncio/base_events.py(1909): _run_once\n/home/vlad/mambaforge/lib/python3.10/asyncio/base_events.py(603): run_forever\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/tornado/platform/asyncio.py(205): start\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel/kernelapp.py(739): start\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/traitlets/config/application.py(1075): launch_instance\n/data/deep/pyvoice_venv/lib/python3.10/site-packages/ipykernel_launcher.py(18): <module>\n/home/vlad/mambaforge/lib/python3.10/runpy.py(86): _run_code\n/home/vlad/mambaforge/lib/python3.10/runpy.py(196): _run_module_as_main\n)\n\n    Inputs:\n        #0: 1060 defined in (%1060 : Float(*, *, *, strides=[32512, 32512, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"reflect\"](%1034, %1059), scope: redimnet.model.ReDimNetWrap::/redimnet.layers.features.MelBanks::spec/torch.nn.modules.container.Sequential::torchfbank/torchaudio.transforms._transforms.MelSpectrogram::torchfbank.2/torchaudio.transforms._transforms.Spectrogram::spectrogram # /data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/nn/functional.py:5209:0\n    )  (type 'Tensor')\n        #1: 1070 defined in (%1070 : int[] = prim::ListConstruct(%1064, %1069), scope: redimnet.model.ReDimNetWrap::/redimnet.layers.features.MelBanks::spec/torch.nn.modules.container.Sequential::torchfbank/torchaudio.transforms._transforms.MelSpectrogram::torchfbank.2/torchaudio.transforms._transforms.Spectrogram::spectrogram\n    )  (type 'List[int]')\n    Outputs:\n        #0: 1071 defined in (%1071 : Float(*, *, strides=[32512, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0](%1060, %1070), scope: redimnet.model.ReDimNetWrap::/redimnet.layers.features.MelBanks::spec/torch.nn.modules.container.Sequential::torchfbank/torchaudio.transforms._transforms.MelSpectrogram::torchfbank.2/torchaudio.transforms._transforms.Spectrogram::spectrogram # /data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/functional.py:708:0\n    )  (type 'Tensor')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m export_onnx_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredimnet_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m dynamic_axes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeats\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membs\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m}}\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_success_redimnet.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel has been converted to ONNX and saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_onnx_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/__init__.py:383\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exporter only supports dynamic shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m     )\n\u001b[0;32m--> 383\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py:495\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;241m+\u001b[39m (kwargs,)\n\u001b[0;32m--> 495\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py:1428\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1425\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1426\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1428\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_opsets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     custom_opsets \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/data/deep/pyvoice_venv/lib/python3.10/site-packages/torch/onnx/utils.py:1068\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _optimize_graph(\n\u001b[1;32m   1058\u001b[0m         graph,\n\u001b[1;32m   1059\u001b[0m         operator_export_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         module\u001b[38;5;241m=\u001b[39mmodule,\n\u001b[1;32m   1066\u001b[0m     )\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1068\u001b[0m     \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_onnx_log\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTorch IR graph at exception: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m is_script \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(model, (torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 32000)  # smaller input\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 3. Export the model to ONNX\n",
    "export_onnx_file = \"redimnet_model.onnx\"\n",
    "dynamic_axes = {'feats': {0: 'B', 1: 'T'}, 'embs': {0: 'B'}}\n",
    "\n",
    "\n",
    "torch.onnx.export(model,\n",
    "    dummy_input,\n",
    "    \"model_success_redimnet.onnx\",\n",
    "    do_constant_folding=True,\n",
    "    verbose=False,\n",
    "    opset_version=17,\n",
    "    input_names=['feats'],\n",
    "    output_names=['embs'],\n",
    "    dynamic_axes=dynamic_axes)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Model has been converted to ONNX and saved at: {export_onnx_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"redimnet_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load ONNX model\n",
    "ort_session = ort.InferenceSession(\"redimnet_model.onnx\")\n",
    "\n",
    "# Generate a random test input\n",
    "test_input = np.random.randn(1, 32000).astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "waveform, sample_rate = torchaudio.load(\"./test00.wav\")\n",
    "outputs = ort_session.run(None, {\"waveform\": waveform})\n",
    "\n",
    "# Print the embedding shape\n",
    "print(\"ONNX Model Output Shape:\", np.array(outputs[0]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
