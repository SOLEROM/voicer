{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /data/proj/voice/redimnet/models/IDRnD_ReDimNet_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/redimnet/models/IDRnD_ReDimNet_master\n",
      "load_res : <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# model_name='B0'\n",
    "# train_type='ft_lm'\n",
    "# dataset='vox2'\n",
    "\n",
    "model_name='b2' # ~b2\n",
    "train_type='ptn'\n",
    "dataset='vox2'\n",
    "\n",
    "torch.hub.set_dir('/data/proj/voice/redimnet/models')\n",
    "\n",
    "original_model = torch.hub.load('IDRnD/ReDimNet', 'ReDimNet', \n",
    "                       model_name=model_name, \n",
    "                       train_type=train_type, \n",
    "                       dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/redimnet/models/IDRnD_ReDimNet_master/redimnet/layers/features.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ReDimNetWrap                                                 [1, 192]                  --\n",
       "├─MelBanks: 1-1                                              [1, 72, 134]              --\n",
       "│    └─Sequential: 2-1                                       [1, 72, 134]              --\n",
       "│    │    └─Identity: 3-1                                    [1, 32000]                --\n",
       "│    │    └─PreEmphasis: 3-2                                 [1, 32000]                --\n",
       "│    │    └─MelSpectrogram: 3-3                              [1, 72, 134]              --\n",
       "├─ReDimNet: 1-2                                              [1, 1152, 134]            --\n",
       "│    └─Sequential: 2-2                                       [1, 1152, 134]            --\n",
       "│    │    └─Conv2d: 3-4                                      [1, 16, 72, 134]          160\n",
       "│    │    └─LayerNorm: 3-5                                   [1, 16, 72, 134]          32\n",
       "│    │    └─to1d: 3-6                                        [1, 1152, 134]            --\n",
       "│    └─Sequential: 2-3                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-7                                    [1, 1152, 134]            (1)\n",
       "│    │    └─to2d: 3-8                                        [1, 16, 72, 134]          --\n",
       "│    │    └─Conv2d: 3-9                                      [1, 16, 72, 134]          272\n",
       "│    │    └─ConvBlock2d: 3-10                                [1, 16, 72, 134]          896\n",
       "│    │    └─ConvBlock2d: 3-11                                [1, 16, 72, 134]          896\n",
       "│    │    └─to1d: 3-12                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-13                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-4                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-14                                   [1, 1152, 134]            2,304\n",
       "│    │    └─to2d: 3-15                                       [1, 16, 72, 134]          --\n",
       "│    │    └─Conv2d: 3-16                                     [1, 32, 36, 134]          1,056\n",
       "│    │    └─ConvBlock2d: 3-17                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-18                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─to1d: 3-19                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-20                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-5                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-21                                   [1, 1152, 134]            3,456\n",
       "│    │    └─to2d: 3-22                                       [1, 32, 36, 134]          --\n",
       "│    │    └─Conv2d: 3-23                                     [1, 32, 36, 134]          1,056\n",
       "│    │    └─ConvBlock2d: 3-24                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-25                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-26                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─to1d: 3-27                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-28                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-6                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-29                                   [1, 1152, 134]            4,608\n",
       "│    │    └─to2d: 3-30                                       [1, 32, 36, 134]          --\n",
       "│    │    └─Conv2d: 3-31                                     [1, 96, 12, 134]          9,312\n",
       "│    │    └─ConvBlock2d: 3-32                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-33                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-34                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-35                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─to1d: 3-36                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-37                         [1, 1152, 134]            561,168\n",
       "│    └─Sequential: 2-7                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-38                                   [1, 1152, 134]            5,760\n",
       "│    │    └─to2d: 3-39                                       [1, 96, 12, 134]          --\n",
       "│    │    └─Conv2d: 3-40                                     [1, 96, 12, 134]          9,312\n",
       "│    │    └─ConvBlock2d: 3-41                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-42                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-43                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-44                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─to1d: 3-45                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-46                         [1, 1152, 134]            561,168\n",
       "│    └─Sequential: 2-8                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-47                                   [1, 1152, 134]            6,912\n",
       "│    │    └─to2d: 3-48                                       [1, 96, 12, 134]          --\n",
       "│    │    └─Conv2d: 3-49                                     [1, 192, 6, 134]          37,056\n",
       "│    │    └─ConvBlock2d: 3-50                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-51                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-52                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-53                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─to1d: 3-54                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-55                         [1, 1152, 134]            1,535,904\n",
       "│    └─weigth1d: 2-9                                         [1, 1152, 134]            8,064\n",
       "│    └─Identity: 2-10                                        [1, 1152, 134]            --\n",
       "│    └─Identity: 2-11                                        [1, 1152, 134]            --\n",
       "├─ASTP: 1-3                                                  [1, 2304]                 --\n",
       "│    └─Conv1d: 2-12                                          [1, 128, 134]             442,496\n",
       "│    └─Conv1d: 2-13                                          [1, 1152, 134]            148,608\n",
       "├─BatchNorm1d: 1-4                                           [1, 2304]                 4,608\n",
       "├─Linear: 1-5                                                [1, 192]                  442,560\n",
       "==============================================================================================================\n",
       "Total params: 5,067,057\n",
       "Trainable params: 5,067,056\n",
       "Non-trainable params: 1\n",
       "Total mult-adds (M): 896.54\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 118.09\n",
       "Params size (MB): 20.27\n",
       "Estimated Total Size (MB): 138.49\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(original_model, input_size=(1, 32000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see MelSpectrogram inside the model ; lets take it outside the model;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone => ReDimNet(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): LayerNorm(C=(16,), data_format=channels_first, eps=1e-06)\n",
      "    (2): to1d()\n",
      "  )\n",
      "  (stage0): Sequential(\n",
      "    (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
      "    (1): to2d(f=72,c=16)\n",
      "    (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
      "        )\n",
      "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
      "        )\n",
      "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): to1d()\n",
      "    (6): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage1): Sequential(\n",
      "    (0): weigth1d(w=(1, 2, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=72,c=16)\n",
      "    (2): Conv2d(16, 32, kernel_size=(2, 1), stride=(2, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): to1d()\n",
      "    (6): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (0): weigth1d(w=(1, 3, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=36,c=32)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): to1d()\n",
      "    (7): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): weigth1d(w=(1, 4, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=36,c=32)\n",
      "    (2): Conv2d(32, 96, kernel_size=(3, 1), stride=(3, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): to1d()\n",
      "    (8): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): weigth1d(w=(1, 5, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=12,c=96)\n",
      "    (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): to1d()\n",
      "    (8): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage5): Sequential(\n",
      "    (0): weigth1d(w=(1, 6, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=12,c=96)\n",
      "    (2): Conv2d(96, 192, kernel_size=(2, 1), stride=(2, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): to1d()\n",
      "    (8): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 288, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(288,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(7,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(19,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(31,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(59,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (v_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (q_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (out_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(288, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (fin_wght1d): weigth1d(w=(1, 7, 1152, 1),sequential=False)\n",
      "  (mfa): Identity()\n",
      "  (fin_to2d): Identity()\n",
      ")\n",
      "spec => MelBanks(\n",
      "  (torchfbank): Sequential(\n",
      "    (0): Identity()\n",
      "    (1): PreEmphasis()\n",
      "    (2): MelSpectrogram(\n",
      "      (spectrogram): Spectrogram()\n",
      "      (mel_scale): MelScale()\n",
      "    )\n",
      "  )\n",
      "  (specaug): Identity()\n",
      ")\n",
      "pool => ASTP(\n",
      "  (linear1): Conv1d(3456, 128, kernel_size=(1,), stride=(1,))\n",
      "  (linear2): Conv1d(128, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "bn => BatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "linear => Linear(in_features=2304, out_features=192, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in original_model.named_children():\n",
    "    print(name, \"=>\", module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReDimNetNoMel(\n",
       "  (backbone): ReDimNet(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): LayerNorm(C=(16,), data_format=channels_first, eps=1e-06)\n",
       "      (2): to1d()\n",
       "    )\n",
       "    (stage0): Sequential(\n",
       "      (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=16)\n",
       "      (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
       "          )\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
       "          )\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): weigth1d(w=(1, 2, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=16)\n",
       "      (2): Conv2d(16, 32, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): weigth1d(w=(1, 3, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=32)\n",
       "      (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): to1d()\n",
       "      (7): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): weigth1d(w=(1, 4, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=32)\n",
       "      (2): Conv2d(32, 96, kernel_size=(3, 1), stride=(3, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): weigth1d(w=(1, 5, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=12,c=96)\n",
       "      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage5): Sequential(\n",
       "      (0): weigth1d(w=(1, 6, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=12,c=96)\n",
       "      (2): Conv2d(96, 192, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(288,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(7,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(19,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(31,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(59,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (v_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (q_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (out_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(288, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (fin_wght1d): weigth1d(w=(1, 7, 1152, 1),sequential=False)\n",
       "    (mfa): Identity()\n",
       "    (fin_to2d): Identity()\n",
       "  )\n",
       "  (pool): ASTP(\n",
       "    (linear1): Conv1d(3456, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1152, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=2304, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# 2) Define a Model Class without MelBanks\n",
    "########################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ReDimNetNoMel(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper around the original ReDimNetWrap that:\n",
    "      - Excludes the 'spec' (MelBanks) module\n",
    "      - Uses 'backbone', 'pool', 'bn', and 'linear'\n",
    "    We expect a precomputed mel spectrogram as input with shape [B, 1, n_mels, time_frames].\n",
    "    \"\"\"\n",
    "    def __init__(self, original_wrap):\n",
    "        super().__init__()\n",
    "        # Grab references to the submodules we want to keep\n",
    "        self.backbone = original_wrap.backbone\n",
    "        self.pool = original_wrap.pool\n",
    "        self.bn = original_wrap.bn\n",
    "        self.linear = original_wrap.linear\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: shape [B, 1, n_mels, time_frames]\n",
    "        # (1) Pass through the backbone\n",
    "        x = self.backbone(x)    # shape might become [B, channels, frames] or similar\n",
    "        # (2) Pooling\n",
    "        x = self.pool(x)        # ASTP => shape likely [B, embedding_dim]\n",
    "        # (3) BatchNorm\n",
    "        x = self.bn(x)\n",
    "        # (4) Final linear => 192-dim (if that's your embedding size)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of our new model that skips the MelBanks front-end\n",
    "model_no_mel = ReDimNetNoMel(original_model)\n",
    "model_no_mel.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 72, 134])\n"
     ]
    }
   ],
   "source": [
    "mel = original_model.spec(torch.randn(1, 32000))  # input: fake waveform\n",
    "print(mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ReDimNetNoMel                                                [1, 192]                  --\n",
       "├─ReDimNet: 1-1                                              [1, 1152, 134]            --\n",
       "│    └─Sequential: 2-1                                       [1, 1152, 134]            --\n",
       "│    │    └─Conv2d: 3-1                                      [1, 16, 72, 134]          160\n",
       "│    │    └─LayerNorm: 3-2                                   [1, 16, 72, 134]          32\n",
       "│    │    └─to1d: 3-3                                        [1, 1152, 134]            --\n",
       "│    └─Sequential: 2-2                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-4                                    [1, 1152, 134]            (1)\n",
       "│    │    └─to2d: 3-5                                        [1, 16, 72, 134]          --\n",
       "│    │    └─Conv2d: 3-6                                      [1, 16, 72, 134]          272\n",
       "│    │    └─ConvBlock2d: 3-7                                 [1, 16, 72, 134]          896\n",
       "│    │    └─ConvBlock2d: 3-8                                 [1, 16, 72, 134]          896\n",
       "│    │    └─to1d: 3-9                                        [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-10                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-3                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-11                                   [1, 1152, 134]            2,304\n",
       "│    │    └─to2d: 3-12                                       [1, 16, 72, 134]          --\n",
       "│    │    └─Conv2d: 3-13                                     [1, 32, 36, 134]          1,056\n",
       "│    │    └─ConvBlock2d: 3-14                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-15                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─to1d: 3-16                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-17                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-4                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-18                                   [1, 1152, 134]            3,456\n",
       "│    │    └─to2d: 3-19                                       [1, 32, 36, 134]          --\n",
       "│    │    └─Conv2d: 3-20                                     [1, 32, 36, 134]          1,056\n",
       "│    │    └─ConvBlock2d: 3-21                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-22                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-23                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─to1d: 3-24                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-25                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-5                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-26                                   [1, 1152, 134]            4,608\n",
       "│    │    └─to2d: 3-27                                       [1, 32, 36, 134]          --\n",
       "│    │    └─Conv2d: 3-28                                     [1, 96, 12, 134]          9,312\n",
       "│    │    └─ConvBlock2d: 3-29                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-30                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-31                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-32                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─to1d: 3-33                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-34                         [1, 1152, 134]            561,168\n",
       "│    └─Sequential: 2-6                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-35                                   [1, 1152, 134]            5,760\n",
       "│    │    └─to2d: 3-36                                       [1, 96, 12, 134]          --\n",
       "│    │    └─Conv2d: 3-37                                     [1, 96, 12, 134]          9,312\n",
       "│    │    └─ConvBlock2d: 3-38                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-39                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-40                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-41                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─to1d: 3-42                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-43                         [1, 1152, 134]            561,168\n",
       "│    └─Sequential: 2-7                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-44                                   [1, 1152, 134]            6,912\n",
       "│    │    └─to2d: 3-45                                       [1, 96, 12, 134]          --\n",
       "│    │    └─Conv2d: 3-46                                     [1, 192, 6, 134]          37,056\n",
       "│    │    └─ConvBlock2d: 3-47                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-48                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-49                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-50                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─to1d: 3-51                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-52                         [1, 1152, 134]            1,535,904\n",
       "│    └─weigth1d: 2-8                                         [1, 1152, 134]            8,064\n",
       "│    └─Identity: 2-9                                         [1, 1152, 134]            --\n",
       "│    └─Identity: 2-10                                        [1, 1152, 134]            --\n",
       "├─ASTP: 1-2                                                  [1, 2304]                 --\n",
       "│    └─Conv1d: 2-11                                          [1, 128, 134]             442,496\n",
       "│    └─Conv1d: 2-12                                          [1, 1152, 134]            148,608\n",
       "├─BatchNorm1d: 1-3                                           [1, 2304]                 4,608\n",
       "├─Linear: 1-4                                                [1, 192]                  442,560\n",
       "==============================================================================================================\n",
       "Total params: 5,067,057\n",
       "Trainable params: 5,067,056\n",
       "Non-trainable params: 1\n",
       "Total mult-adds (M): 896.54\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.04\n",
       "Forward/backward pass size (MB): 118.09\n",
       "Params size (MB): 20.27\n",
       "Estimated Total Size (MB): 138.40\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = torch.randn(1, 1, 72, 134)\n",
    "summary(model_no_mel, input_data=example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function for WAV -> MelSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def waveform_to_logmel(\n",
    "    waveform: torch.Tensor,\n",
    "    sample_rate: int = 16000,\n",
    "    n_fft: int = 512,\n",
    "    hop_length: int = 160,\n",
    "    n_mels: int = 72,       ## 72 for vox2 ;  60 for B0\n",
    "    f_min: float = 20.0,\n",
    "    f_max: float = 8000.0,\n",
    "    preemphasis_alpha: float = 0.97\n",
    "):\n",
    "    \"\"\"\n",
    "    Reproduces the main logic of 'NormalizeAudio', 'PreEmphasis',\n",
    "    and 'MelSpectrogram' from the 'MelBanks' layer.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) NormalizeAudio\n",
    "    waveform = waveform / (waveform.abs().max() + 1e-8)\n",
    "\n",
    "    # 2) PreEmphasis\n",
    "    shifted = torch.roll(waveform, shifts=1, dims=1)\n",
    "    waveform_preemph = waveform - preemphasis_alpha * shifted\n",
    "    # fix first sample\n",
    "    waveform_preemph[:, 0] = waveform[:, 0]\n",
    "\n",
    "    # 3) MelSpectrogram\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        f_min=f_min,\n",
    "        f_max=f_max,\n",
    "        power=2.0,\n",
    "        center=False\n",
    "    )\n",
    "    mel_spec = mel_transform(waveform_preemph)  # shape: [channel=1, n_mels, time_frames]\n",
    "\n",
    "    # Log scale\n",
    "    log_mel = torch.log(mel_spec + 1e-6)\n",
    "    return log_mel  # shape: [1, n_mels, time_frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_inference(wav_path: str):\n",
    "    # (a) Load audio\n",
    "    waveform, sr = torchaudio.load(wav_path)  # shape: [channels, time]\n",
    "    # If stereo, select one channel, or average:\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # (b) Convert to log-mel\n",
    "    log_mel = waveform_to_logmel(waveform, sample_rate=sr)\n",
    "    # Now log_mel shape is [1, n_mels, time_frames].\n",
    "\n",
    "    # (c) Model expects a batch, so add batch dim => [B=1, 1, n_mels, time_frames]\n",
    "    log_mel = log_mel.unsqueeze(0)\n",
    "    print(\"log_mel shape:\", log_mel.shape)\n",
    "\n",
    "\n",
    "    # (d) Forward pass\n",
    "    with torch.no_grad():\n",
    "        embedding = model_no_mel(log_mel)  # shape typically [1, 192] or so\n",
    "\n",
    "    print(\"Embedding shape:\", embedding.shape)\n",
    "    #print(\"Embedding:\", embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity between two embeddings\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1, embedding2).item()\n",
    "\n",
    "def cosine_similarity_numpys(emb1: np.ndarray, emb2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors of shape (D,) or (1, D).\n",
    "    \"\"\"\n",
    "    # If shape is (1, D), flatten to (D,)\n",
    "    v1 = emb1.flatten()\n",
    "    v2 = emb2.flatten()\n",
    "\n",
    "    # dot product\n",
    "    dot = np.dot(v1, v2)\n",
    "    # norms\n",
    "    norm1 = np.linalg.norm(v1)\n",
    "    norm2 = np.linalg.norm(v2)\n",
    "\n",
    "    # Add a small epsilon in case of very small norms\n",
    "    sim = dot / (norm1 * norm2 + 1e-8)\n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_mel shape: torch.Size([1, 1, 72, 219])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "log_mel shape: torch.Size([1, 1, 72, 200])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "log_mel shape: torch.Size([1, 1, 72, 5057])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (72) may be set too high. Or, the value for `n_freqs` (257) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([1, 192])\n",
      "Similarity: 0.868979275226593\n",
      "Similarity: 0.49476510286331177\n"
     ]
    }
   ],
   "source": [
    "embed1 = example_inference(\"test00.wav\")\n",
    "embed2 = example_inference(\"test01.wav\")\n",
    "embed3 = example_inference(\"test2.wav\")\n",
    "\n",
    "print(f\"Similarity: {cosine_similarity(embed1, embed2)}\")\n",
    "print(f\"Similarity: {cosine_similarity(embed1, embed3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to ReDimNet_no_mel.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "def export_to_onnx(model, onnx_path=\"ReDimNet_no_mel.onnx\"):\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a dummy input with shape matching [B=1, 1, n_mels=72, time_frames=200] (example)\n",
    "    dummy_input = torch.randn(1, 1, 72, 200)\n",
    "    \n",
    "    ##  fixed-length segments \n",
    "    # torch.onnx.export(\n",
    "    #     model,\n",
    "    #     dummy_input,\n",
    "    #     onnx_path,\n",
    "    #     input_names=[\"log_mel\"],\n",
    "    #     output_names=[\"embedding\"],\n",
    "    #     opset_version=11\n",
    "    # )\n",
    "    # print(\"Exported to\", onnx_path)\n",
    "    \n",
    "    ## Export with Dynamic Axis\n",
    "    torch.onnx.export(\n",
    "        model_no_mel,                 # your model\n",
    "        dummy_input,                  # e.g. shape [1, 1, 60, 200]\n",
    "        \"ReDimNet_no_mel.onnx\",\n",
    "        input_names=[\"log_mel\"],\n",
    "        output_names=[\"embedding\"],\n",
    "        opset_version=19,\n",
    "        dynamic_axes={\n",
    "            \"log_mel\": {0: \"batch_size\", 3: \"time_frames\"},\n",
    "            \"embedding\": {0: \"batch_size\"}\n",
    "        }\n",
    "    )\n",
    "    print(\"Exported to\", onnx_path)\n",
    "\n",
    "# Example usage\n",
    "export_to_onnx(model_no_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 vlad vlad 20M May 30 17:30 ReDimNet_no_mel.onnx\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ReDimNet_no_mel.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"ReDimNet_no_mel.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveform_to_logmel(\n",
    "    waveform: torch.Tensor,\n",
    "    sample_rate=16000,\n",
    "    n_fft=512,\n",
    "    hop_length=160,\n",
    "    n_mels=72,         # match whatever your model expects\n",
    "    f_min=20.0,\n",
    "    f_max=8000.0,\n",
    "    preemphasis_alpha=0.97\n",
    "):\n",
    "    # 1) Normalize\n",
    "    waveform = waveform / (waveform.abs().max() + 1e-8)\n",
    "    # 2) PreEmphasis\n",
    "    shifted = torch.roll(waveform, shifts=1, dims=1)\n",
    "    waveform_preemph = waveform - preemphasis_alpha * shifted\n",
    "    waveform_preemph[:, 0] = waveform[:, 0]\n",
    "    # 3) MelSpectrogram\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        f_min=f_min,\n",
    "        f_max=f_max,\n",
    "        power=2.0,\n",
    "        center=False\n",
    "    )\n",
    "    mel_spec = mel_transform(waveform_preemph)\n",
    "    # 4) Log scale\n",
    "    log_mel = torch.log(mel_spec + 1e-6)\n",
    "    return log_mel  # shape: [1, n_mels, frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "def run_inference_onnx(onnx_path, wav_path):\n",
    "    \"\"\"\n",
    "    Loads an audio file, converts to log-mel, and runs inference\n",
    "    in an ONNX session. Returns the embedding as a NumPy array.\n",
    "    \"\"\"\n",
    "    #######################################\n",
    "    # 1) Load your ONNX model\n",
    "    #######################################\n",
    "    # (Optional) onnx.checker to confirm it’s valid\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(f\"Loaded and checked ONNX model from: {onnx_path}\")\n",
    "\n",
    "    # Create an inference session\n",
    "    session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "    # Usually we retrieve the first input & output name\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "    #######################################\n",
    "    # 2) Load audio, get log-mel\n",
    "    #######################################\n",
    "    waveform, sr = torchaudio.load(wav_path)\n",
    "    # If multi-channel, downmix:\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    log_mel = waveform_to_logmel(waveform, sample_rate=sr)\n",
    "    # Insert a batch dimension => shape [B, 1, n_mels, frames]\n",
    "    log_mel = log_mel.unsqueeze(0)  # => [1, 1, n_mels, time_frames]\n",
    "\n",
    "    #######################################\n",
    "    # 3) ONNX Inference\n",
    "    #######################################\n",
    "    # Convert to NumPy for ONNX runtime\n",
    "    log_mel_np = log_mel.cpu().numpy()\n",
    "    # Run inference\n",
    "    outputs = session.run([output_name], {input_name: log_mel_np})\n",
    "    # outputs is a list; typically we want the first item\n",
    "    embedding = outputs[0]  # shape is [1, embedding_dim]\n",
    "\n",
    "    print(\"Embedding shape:\", embedding.shape)\n",
    "    # print(\"Embedding data:\\n\", embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "Embedding shape: (1, 192)\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "Embedding shape: (1, 192)\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "Embedding shape: (1, 192)\n",
      "Similarity: 0.8689795136451721\n",
      "Similarity: 0.49476543068885803\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path = \"ReDimNet_no_mel.onnx\"\n",
    "\n",
    "embed1 = run_inference_onnx(onnx_model_path, \"test00.wav\")\n",
    "embed2 = run_inference_onnx(onnx_model_path, \"test01.wav\")\n",
    "embed3 = run_inference_onnx(onnx_model_path, \"test2.wav\")\n",
    "\n",
    "print(f\"Similarity: {cosine_similarity_numpys(embed1, embed2)}\")\n",
    "print(f\"Similarity: {cosine_similarity_numpys(embed1, embed3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cal data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fake cal data ; TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in range(100):\n",
    "    dummy = np.random.rand(1, 1, 60, 134).astype('float32')\n",
    "    np.save(f'cal/sample_{i}.npy', dummy)\n",
    "\n",
    "with open('cal/dataset.txt', 'w') as f:\n",
    "    for i in range(100):\n",
    "        f.write(f'sample_{i}.npy\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvoice_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
