{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReDimNetNoMel Disable bad layers\n",
    "\n",
    "===============================================================\n",
    "\n",
    "* build new noMel model based on base line\n",
    "* turn off bad layers that not converting to identity\n",
    "* store to onnx and test to convert\n",
    "* no need to run voice through as the identity layers kill the wights and the model output is garbage\n",
    "==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "## our utils\n",
    "from utils.common_import import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import my_utils as myUtils\n",
    "from play1_setBase_line_B0 import original_model,base_line_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReDimNetWrap expects raw 16 kHz mono audio, exactly 32 000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ReDimNetWrap                                                 [1, 192]                  --\n",
       "├─MelBanks: 1-1                                              [1, 60, 134]              --\n",
       "│    └─Sequential: 2-1                                       [1, 60, 134]              --\n",
       "│    │    └─Identity: 3-1                                    [1, 32000]                --\n",
       "│    │    └─PreEmphasis: 3-2                                 [1, 32000]                --\n",
       "│    │    └─MelSpectrogram: 3-3                              [1, 60, 134]              --\n",
       "├─ReDimNet: 1-2                                              [1, 600, 134]             --\n",
       "│    └─Sequential: 2-2                                       [1, 600, 134]             --\n",
       "│    │    └─Conv2d: 3-4                                      [1, 10, 60, 134]          100\n",
       "│    │    └─LayerNorm: 3-5                                   [1, 10, 60, 134]          20\n",
       "│    │    └─to1d: 3-6                                        [1, 600, 134]             --\n",
       "│    └─Sequential: 2-3                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-7                                    [1, 600, 134]             (1)\n",
       "│    │    └─to2d: 3-8                                        [1, 10, 60, 134]          --\n",
       "│    │    └─Conv2d: 3-9                                      [1, 10, 60, 134]          110\n",
       "│    │    └─ConvBlock2d: 3-10                                [1, 10, 60, 134]          440\n",
       "│    │    └─ConvBlock2d: 3-11                                [1, 10, 60, 134]          440\n",
       "│    │    └─to1d: 3-12                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-13                         [1, 600, 134]             31,500\n",
       "│    └─Sequential: 2-4                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-14                                   [1, 600, 134]             1,200\n",
       "│    │    └─to2d: 3-15                                       [1, 10, 60, 134]          --\n",
       "│    │    └─Conv2d: 3-16                                     [1, 40, 30, 134]          840\n",
       "│    │    └─ConvBlock2d: 3-17                                [1, 40, 30, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-18                                [1, 40, 30, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-19                                [1, 40, 30, 134]          4,160\n",
       "│    │    └─Sequential: 3-20                                 [1, 20, 30, 134]          840\n",
       "│    │    └─to1d: 3-21                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-22                         [1, 600, 134]             31,500\n",
       "│    └─Sequential: 2-5                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-23                                   [1, 600, 134]             1,800\n",
       "│    │    └─to2d: 3-24                                       [1, 20, 30, 134]          --\n",
       "│    │    └─Conv2d: 3-25                                     [1, 60, 30, 134]          1,260\n",
       "│    │    └─ConvBlock2d: 3-26                                [1, 60, 30, 134]          8,640\n",
       "│    │    └─ConvBlock2d: 3-27                                [1, 60, 30, 134]          8,640\n",
       "│    │    └─ConvBlock2d: 3-28                                [1, 60, 30, 134]          8,640\n",
       "│    │    └─Sequential: 3-29                                 [1, 20, 30, 134]          1,020\n",
       "│    │    └─to1d: 3-30                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-31                         [1, 600, 134]             31,500\n",
       "│    └─Sequential: 2-6                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-32                                   [1, 600, 134]             2,400\n",
       "│    │    └─to2d: 3-33                                       [1, 20, 30, 134]          --\n",
       "│    │    └─Conv2d: 3-34                                     [1, 80, 15, 134]          3,280\n",
       "│    │    └─ConvBlock2d: 3-35                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─ConvBlock2d: 3-36                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─ConvBlock2d: 3-37                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─ConvBlock2d: 3-38                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─Sequential: 3-39                                 [1, 40, 15, 134]          2,480\n",
       "│    │    └─to1d: 3-40                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-41                         [1, 600, 134]             117,300\n",
       "│    └─Sequential: 2-7                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-42                                   [1, 600, 134]             3,000\n",
       "│    │    └─to2d: 3-43                                       [1, 40, 15, 134]          --\n",
       "│    │    └─Conv2d: 3-44                                     [1, 40, 15, 134]          1,640\n",
       "│    │    └─ConvBlock2d: 3-45                                [1, 40, 15, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-46                                [1, 40, 15, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-47                                [1, 40, 15, 134]          4,160\n",
       "│    │    └─to1d: 3-48                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-49                         [1, 600, 134]             117,300\n",
       "│    └─weigth1d: 2-8                                         [1, 600, 134]             3,600\n",
       "│    └─Identity: 2-9                                         [1, 600, 134]             --\n",
       "│    └─Identity: 2-10                                        [1, 600, 134]             --\n",
       "├─ASTP: 1-3                                                  [1, 1200]                 --\n",
       "│    └─Conv1d: 2-11                                          [1, 128, 134]             230,528\n",
       "│    └─Conv1d: 2-12                                          [1, 600, 134]             77,400\n",
       "├─BatchNorm1d: 1-4                                           [1, 1200]                 2,400\n",
       "├─Linear: 1-5                                                [1, 192]                  230,592\n",
       "==============================================================================================================\n",
       "Total params: 1,004,251\n",
       "Trainable params: 1,004,250\n",
       "Non-trainable params: 1\n",
       "Total mult-adds (M): 406.29\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 133.03\n",
       "Params size (MB): 4.02\n",
       "Estimated Total Size (MB): 137.18\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(original_model, input_size=(1, 32000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  new model with Identity layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 2) Define a Model Class without MelBanks\n",
    "########################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ReDimNetNoMel(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper around the original ReDimNetWrap that:\n",
    "      - Excludes the 'spec' (MelBanks) module\n",
    "      - Uses 'backbone', 'pool', 'bn', and 'linear'\n",
    "    We expect a precomputed mel spectrogram as input with shape [B, 1, n_mels, time_frames].\n",
    "    \"\"\"\n",
    "    def __init__(self, original_wrap):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Grab references to the submodules we want to keep\n",
    "        self.backbone = original_wrap.backbone\n",
    "        \n",
    "        \n",
    "        ## DESERT SEARCH WHAT HANGS ###\n",
    "        # self.backbone.stage0[6] = nn.Identity()\n",
    "        # self.backbone.stage1[8] = nn.Identity()\n",
    "        # self.backbone.stage2[8] = nn.Identity()\n",
    "        # self.backbone.stage3[9] = nn.Identity()\n",
    "        # self.backbone.stage4[7] = nn.Identity()\n",
    "        ### >>>> PASS\n",
    "        \n",
    "        # try: only close TransformerEncoderLayer\n",
    "        # self.backbone.stage0[6].tcm[4] = nn.Identity()\n",
    "        # self.backbone.stage1[8].tcm[4] = nn.Identity()\n",
    "        # self.backbone.stage2[8].tcm[4] = nn.Identity()\n",
    "        # self.backbone.stage3[9].tcm[4] = nn.Identity()\n",
    "        # self.backbone.stage4[7].tcm[4] = nn.Identity()\n",
    "        # >>>> NOT PASS\n",
    "        \n",
    "        # try: close only 1 ConvNeXtLikeBlock\n",
    "        # self.backbone.stage0[6].tcm[0] = nn.Identity()\n",
    "        # self.backbone.stage1[8].tcm[0] = nn.Identity()\n",
    "        # self.backbone.stage2[8].tcm[0] = nn.Identity()\n",
    "        # self.backbone.stage3[9].tcm[0] = nn.Identity()\n",
    "        # self.backbone.stage4[7].tcm[0] = nn.Identity()\n",
    "        # >>> NOT PASS\n",
    "        \n",
    "        ## try: all layers of ConvNeXtLikeBlock\n",
    "        for stage_idx, block_idx in [(0, 6), (1, 8), (2, 8), (3, 9), (4, 7)]:\n",
    "            for tcm_idx in range(4):  # tcm[0] to tcm[3] \n",
    "                # self.backbone.__getattr__(f'stage{stage_idx}')[block_idx].tcm[tcm_idx] = nn.Identity()            ## >>>> PASS\n",
    "                # self.backbone.__getattr__(f'stage{stage_idx}')[block_idx].tcm[tcm_idx].act = nn.SiLU()            ## >>>> NOT PASS\n",
    "                ## !!! all Conv1d\n",
    "                self.backbone.__getattr__(f'stage{stage_idx}')[block_idx].tcm[tcm_idx].dwconvs[0] = nn.Identity()\n",
    "                self.backbone.__getattr__(f'stage{stage_idx}')[block_idx].tcm[tcm_idx].pwconv1 = nn.Identity()\n",
    "                ## >>>> PASS\n",
    "\n",
    "        \n",
    "        \n",
    "        # Replace ASTP with RKNN-safe version:\n",
    "        self.pool = original_wrap.pool\n",
    "        self.bn = original_wrap.bn\n",
    "        self.linear = original_wrap.linear\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: shape [B, 1, n_mels, time_frames]\n",
    "        # (1) Pass through the backbone\n",
    "        x = self.backbone(x)    # shape might become [B, channels, frames] or similar\n",
    "        print(\"Backbone output shape:\", x.shape)  # ADD THIS LINE\n",
    "        # (2) Pooling\n",
    "        x = self.pool(x)        # ASTP => shape likely [B, embedding_dim]\n",
    "        # (3) BatchNorm\n",
    "        x = self.bn(x)\n",
    "        # (4) Final linear => 192-dim (if that's your embedding size)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of our new model that skips the MelBanks front-end\n",
    "model_no_mel = ReDimNetNoMel(original_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run to see if it works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone output shape: torch.Size([1, 600, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  3.9911,  -1.0193,   1.1549,   0.8218,   1.5639,   2.2639,  -0.2115,\n",
       "           1.1388,   1.6812,   6.1542,   4.8047,   0.9625,  -2.5269,  -5.0245,\n",
       "          -3.7159,   3.9225,  -0.2732,   1.7035,   0.1402,  -5.7757,   3.4241,\n",
       "           1.3984,  -0.4500,  -1.9297,   0.9378,  -1.4857,   4.4311,   0.6974,\n",
       "          -4.4153,  -7.8101,  -2.9793,  -0.8681,  -4.3332,   1.6840,   3.7524,\n",
       "           4.3297,  -0.7436,   0.3217,  -0.9835,   0.7124,   0.8157,   3.0291,\n",
       "          -2.3501,  -1.4309,   4.2975,  -0.3592,  -0.4157,  -2.6449,   4.6884,\n",
       "           3.3947,  -2.5064,  -3.7524,  -3.2379,   2.8387,  -4.2970,  -2.3072,\n",
       "           0.9681,  -0.3885,  -1.5872,  -0.8838,  -4.6249,  -1.2078,   2.1128,\n",
       "           3.8171,   0.4526,   2.6848,   0.2271,   3.8320,  -0.6987,   0.2206,\n",
       "           1.6393,  -5.3172,  -6.0950,  -1.6590,   2.6062,  -1.7630,  -3.3992,\n",
       "           3.4335,   1.3541,  -4.4168,  -5.2642,   3.2618,   1.3587,   7.2146,\n",
       "           0.6793,  -0.4032,  -0.1059,  -1.5760,   0.9331,  -2.4387,  -0.8942,\n",
       "           5.4100,   2.4653,   4.6587,  -3.9108,   1.3346,   0.3749,  -5.6803,\n",
       "          -0.6930,  -7.6900,   3.8745,   2.5646,  -1.8050,  -0.4620,  -0.3971,\n",
       "          -4.8006,   0.9072,   3.4082,   4.1300,  -5.6840,   2.0372,   2.0056,\n",
       "           0.1513,  -0.5155,  -1.1135,   0.6797,   2.9380,  -3.0666,  -3.0156,\n",
       "          -1.9701,  -5.7909,  -0.7806,   2.5991,  -4.3801,  -2.6378,   0.3045,\n",
       "          -1.0425,   3.9109,  -1.4883,  -3.8702,  -2.5550,   5.7440,   4.0872,\n",
       "           3.8985,  -4.4579,  -1.7342,  -0.1760,   1.7232,   2.1212,   1.4166,\n",
       "           1.4616,   1.4123,  -6.3475,   1.7427,  -6.9984,   1.1590,   4.3085,\n",
       "          -0.1356,  -4.2745,   1.6034,   0.2275,  -1.9576,   1.7176,   5.0779,\n",
       "          -2.0783,  -0.2372,   0.4615,   6.0064,   6.1475,   0.3322,  -2.3495,\n",
       "          -1.4756,   1.0883,  -3.5889,  -1.8769,  -1.9175,   3.6599,  -0.1402,\n",
       "          -6.4909,   3.2774,   1.9578,   2.6648,  -0.7779,  -2.0939,  -0.1179,\n",
       "           5.5199,  -0.5002,   2.5797,  -0.4602,  -0.4343,  -1.3038,  -4.2819,\n",
       "         -11.3261,  -2.6487,  -1.1373,  -1.4754,   1.2789,  -2.9536,  -1.7322,\n",
       "          -1.5164,  -2.1604,   0.3490]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mel.eval()  # <- this line is critical!\n",
    "dummy = torch.randn(1, 1, 60, 200)\n",
    "model_no_mel(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layres debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problematic layer tree is:\n",
    "\n",
    "```\n",
    "TimeContextBlock1d\n",
    "├── red_dim_conv (Sequential)\n",
    "│   ├── Conv1d(600 → 60, kernel_size=1)\n",
    "│   └── LayerNorm(C=60, data_format=channels_first)\n",
    "├── tcm (Sequential)\n",
    "│   ├── ConvNeXtLikeBlock (kernel=7)\n",
    "│   │   ├── dwconvs: Conv1d(60 → 60, kernel_size=7, groups=60)\n",
    "│   │   ├── norm: BatchNorm1d(60)\n",
    "│   │   ├── act: GELU\n",
    "│   │   └── pwconv1: Conv1d(60 → 60, kernel_size=1)\n",
    "│   ├── ConvNeXtLikeBlock (kernel=19)\n",
    "│   │   ├── dwconvs: Conv1d(60 → 60, kernel_size=19, groups=60)\n",
    "│   │   ├── norm: BatchNorm1d(60)\n",
    "│   │   ├── act: GELU\n",
    "│   │   └── pwconv1: Conv1d(60 → 60, kernel_size=1)\n",
    "│   ├── ConvNeXtLikeBlock (kernel=31)\n",
    "│   │   ├── dwconvs: Conv1d(60 → 60, kernel_size=31, groups=60)\n",
    "│   │   ├── norm: BatchNorm1d(60)\n",
    "│   │   ├── act: GELU\n",
    "│   │   └── pwconv1: Conv1d(60 → 60, kernel_size=1)\n",
    "│   ├── ConvNeXtLikeBlock (kernel=59)\n",
    "│   │   ├── dwconvs: Conv1d(60 → 60, kernel_size=59, groups=60)\n",
    "│   │   ├── norm: BatchNorm1d(60)\n",
    "│   │   ├── act: GELU\n",
    "│   │   └── pwconv1: Conv1d(60 → 60, kernel_size=1)\n",
    "│   └── TransformerEncoderLayer\n",
    "│       ├── attention (MultiHeadAttention)\n",
    "│       │   ├── k_proj: Linear(60 → 60)\n",
    "│       │   ├── v_proj: Linear(60 → 60)\n",
    "│       │   ├── q_proj: Linear(60 → 60)\n",
    "│       │   └── out_proj: Linear(60 → 60)\n",
    "│       ├── layer_norm: LayerNorm(60)\n",
    "│       ├── feed_forward\n",
    "│       │   ├── intermediate_dropout: Dropout(0.0)\n",
    "│       │   ├── intermediate_dense: Linear(60 → 60)\n",
    "│       │   ├── intermediate_act_fn: NewGELUActivation\n",
    "│       │   ├── output_dense: Linear(60 → 60)\n",
    "│       │   └── output_dropout: Dropout(0.0)\n",
    "│       └── final_layer_norm: LayerNorm(60)\n",
    "└── exp_dim_conv: Conv1d(60 → 600, kernel_size=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Still has LayerNorm at: backbone.stage0.6.tcm.4.layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage0.6.tcm.4.final_layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage1.8.tcm.4.layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage1.8.tcm.4.final_layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage2.8.tcm.4.layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage2.8.tcm.4.final_layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage3.9.tcm.4.layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage3.9.tcm.4.final_layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage4.7.tcm.4.layer_norm\n",
      "❌ Still has LayerNorm at: backbone.stage4.7.tcm.4.final_layer_norm\n"
     ]
    }
   ],
   "source": [
    "for name, module in model_no_mel.named_modules():\n",
    "    if isinstance(module, nn.LayerNorm):\n",
    "        print(\"❌ Still has LayerNorm at:\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage0.6 = ConvNeXtLikeBlock(\n",
      "  (dwconvs): ModuleList(\n",
      "    (0): Identity()\n",
      "  )\n",
      "  (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): GELU(approximate='none')\n",
      "  (pwconv1): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"stage0.6 =\", model_no_mel.backbone.stage4[7].tcm[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReDimNetNoMel(\n",
       "  (backbone): ReDimNet(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): LayerNorm(C=(10,), data_format=channels_first, eps=1e-06)\n",
       "      (2): to1d()\n",
       "    )\n",
       "    (stage0): Sequential(\n",
       "      (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
       "      (1): to2d(f=60,c=10)\n",
       "      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv1pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv2pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv1pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv2pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 20, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(20,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (v_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (q_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (out_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(20, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): weigth1d(w=(1, 2, 600, 1),sequential=False)\n",
       "      (1): to2d(f=60,c=10)\n",
       "      (2): Conv2d(10, 40, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv2d(40, 20, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=20)\n",
       "        (1): BatchNorm2d(20, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 20, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(20,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (v_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (q_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (out_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(20, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): weigth1d(w=(1, 3, 600, 1),sequential=False)\n",
       "      (1): to2d(f=30,c=20)\n",
       "      (2): Conv2d(20, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv1pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv2pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv1pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv2pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv1pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv2pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv2d(60, 20, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=20)\n",
       "        (1): BatchNorm2d(20, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 20, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(20,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (v_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (q_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (out_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(20, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): weigth1d(w=(1, 4, 600, 1),sequential=False)\n",
       "      (1): to2d(f=30,c=20)\n",
       "      (2): Conv2d(20, 80, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Conv2d(80, 40, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=40)\n",
       "        (1): BatchNorm2d(40, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (8): to1d()\n",
       "      (9): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 60, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(60,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (v_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (q_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (out_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(60, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): weigth1d(w=(1, 5, 600, 1),sequential=False)\n",
       "      (1): to2d(f=15,c=40)\n",
       "      (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): to1d()\n",
       "      (7): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 60, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(60,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Identity()\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Identity()\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (v_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (q_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (out_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(60, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (fin_wght1d): weigth1d(w=(1, 6, 600, 1),sequential=False)\n",
       "    (mfa): Identity()\n",
       "    (fin_to2d): Identity()\n",
       "  )\n",
       "  (pool): ASTP(\n",
       "    (linear1): Conv1d(1800, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 600, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=1200, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone output shape: torch.Size([1, 600, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ReDimNetNoMel                                                [1, 192]                  --\n",
       "├─ReDimNet: 1-1                                              [1, 600, 200]             --\n",
       "│    └─Sequential: 2-1                                       [1, 600, 200]             --\n",
       "│    │    └─Conv2d: 3-1                                      [1, 10, 60, 200]          100\n",
       "│    │    └─LayerNorm: 3-2                                   [1, 10, 60, 200]          20\n",
       "│    │    └─to1d: 3-3                                        [1, 600, 200]             --\n",
       "│    └─Sequential: 2-2                                       [1, 600, 200]             --\n",
       "│    │    └─weigth1d: 3-4                                    [1, 600, 200]             (1)\n",
       "│    │    └─to2d: 3-5                                        [1, 10, 60, 200]          --\n",
       "│    │    └─Conv2d: 3-6                                      [1, 10, 60, 200]          110\n",
       "│    │    └─ConvBlock2d: 3-7                                 [1, 10, 60, 200]          440\n",
       "│    │    └─ConvBlock2d: 3-8                                 [1, 10, 60, 200]          440\n",
       "│    │    └─to1d: 3-9                                        [1, 600, 200]             --\n",
       "│    │    └─TimeContextBlock1d: 3-10                         [1, 600, 200]             27,420\n",
       "│    └─Sequential: 2-3                                       [1, 600, 200]             --\n",
       "│    │    └─weigth1d: 3-11                                   [1, 600, 200]             1,200\n",
       "│    │    └─to2d: 3-12                                       [1, 10, 60, 200]          --\n",
       "│    │    └─Conv2d: 3-13                                     [1, 40, 30, 200]          840\n",
       "│    │    └─ConvBlock2d: 3-14                                [1, 40, 30, 200]          4,160\n",
       "│    │    └─ConvBlock2d: 3-15                                [1, 40, 30, 200]          4,160\n",
       "│    │    └─ConvBlock2d: 3-16                                [1, 40, 30, 200]          4,160\n",
       "│    │    └─Sequential: 3-17                                 [1, 20, 30, 200]          840\n",
       "│    │    └─to1d: 3-18                                       [1, 600, 200]             --\n",
       "│    │    └─TimeContextBlock1d: 3-19                         [1, 600, 200]             27,420\n",
       "│    └─Sequential: 2-4                                       [1, 600, 200]             --\n",
       "│    │    └─weigth1d: 3-20                                   [1, 600, 200]             1,800\n",
       "│    │    └─to2d: 3-21                                       [1, 20, 30, 200]          --\n",
       "│    │    └─Conv2d: 3-22                                     [1, 60, 30, 200]          1,260\n",
       "│    │    └─ConvBlock2d: 3-23                                [1, 60, 30, 200]          8,640\n",
       "│    │    └─ConvBlock2d: 3-24                                [1, 60, 30, 200]          8,640\n",
       "│    │    └─ConvBlock2d: 3-25                                [1, 60, 30, 200]          8,640\n",
       "│    │    └─Sequential: 3-26                                 [1, 20, 30, 200]          1,020\n",
       "│    │    └─to1d: 3-27                                       [1, 600, 200]             --\n",
       "│    │    └─TimeContextBlock1d: 3-28                         [1, 600, 200]             27,420\n",
       "│    └─Sequential: 2-5                                       [1, 600, 200]             --\n",
       "│    │    └─weigth1d: 3-29                                   [1, 600, 200]             2,400\n",
       "│    │    └─to2d: 3-30                                       [1, 20, 30, 200]          --\n",
       "│    │    └─Conv2d: 3-31                                     [1, 80, 15, 200]          3,280\n",
       "│    │    └─ConvBlock2d: 3-32                                [1, 80, 15, 200]          14,720\n",
       "│    │    └─ConvBlock2d: 3-33                                [1, 80, 15, 200]          14,720\n",
       "│    │    └─ConvBlock2d: 3-34                                [1, 80, 15, 200]          14,720\n",
       "│    │    └─ConvBlock2d: 3-35                                [1, 80, 15, 200]          14,720\n",
       "│    │    └─Sequential: 3-36                                 [1, 40, 15, 200]          2,480\n",
       "│    │    └─to1d: 3-37                                       [1, 600, 200]             --\n",
       "│    │    └─TimeContextBlock1d: 3-38                         [1, 600, 200]             95,460\n",
       "│    └─Sequential: 2-6                                       [1, 600, 200]             --\n",
       "│    │    └─weigth1d: 3-39                                   [1, 600, 200]             3,000\n",
       "│    │    └─to2d: 3-40                                       [1, 40, 15, 200]          --\n",
       "│    │    └─Conv2d: 3-41                                     [1, 40, 15, 200]          1,640\n",
       "│    │    └─ConvBlock2d: 3-42                                [1, 40, 15, 200]          4,160\n",
       "│    │    └─ConvBlock2d: 3-43                                [1, 40, 15, 200]          4,160\n",
       "│    │    └─ConvBlock2d: 3-44                                [1, 40, 15, 200]          4,160\n",
       "│    │    └─to1d: 3-45                                       [1, 600, 200]             --\n",
       "│    │    └─TimeContextBlock1d: 3-46                         [1, 600, 200]             95,460\n",
       "│    └─weigth1d: 2-7                                         [1, 600, 200]             3,600\n",
       "│    └─Identity: 2-8                                         [1, 600, 200]             --\n",
       "│    └─Identity: 2-9                                         [1, 600, 200]             --\n",
       "├─ASTP: 1-2                                                  [1, 1200]                 --\n",
       "│    └─Conv1d: 2-10                                          [1, 128, 200]             230,528\n",
       "│    └─Conv1d: 2-11                                          [1, 600, 200]             77,400\n",
       "├─BatchNorm1d: 1-3                                           [1, 1200]                 2,400\n",
       "├─Linear: 1-4                                                [1, 192]                  230,592\n",
       "==============================================================================================================\n",
       "Total params: 948,331\n",
       "Trainable params: 948,330\n",
       "Non-trainable params: 1\n",
       "Total mult-adds (M): 595.07\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 196.25\n",
       "Params size (MB): 3.79\n",
       "Estimated Total Size (MB): 200.09\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_no_mel, (1, 1, 60, 200))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone output shape: torch.Size([1, 600, 134])\n",
      "Exported to ReDimNet_no_mel.onnx\n",
      "-rw-rw-r-- 1 vlad vlad 3.9M Jun 18 18:33 ReDimNet_no_mel.onnx\n"
     ]
    }
   ],
   "source": [
    "myUtils.export_to_onnx(model_no_mel,onnx_path = \"ReDimNet_no_mel.onnx\")\n",
    "!ls -lah ReDimNet_no_mel.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"ReDimNet_no_mel.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvoice_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
