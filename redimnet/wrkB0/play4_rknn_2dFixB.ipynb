{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RKNN fixed version (noMel/conv1d/activation)\n",
    "\n",
    "\n",
    "===============================================================\n",
    "\n",
    "* build new noMel model based on base line\n",
    "* replace bad layers with working layers\n",
    "    * no need to change the width of the layers\n",
    "* run voices through the model and compare to baseline\n",
    "\n",
    "==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "## our utils\n",
    "from utils.common_import import *\n",
    "from utils.test_all_voices import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import my_utils as myUtils\n",
    "from play1_setBase_line_B0 import original_model,base_line_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT_TYPES = (\n",
    "    nn.ReLU, nn.ReLU6, nn.LeakyReLU, nn.ELU, nn.PReLU, nn.GELU,\n",
    "    nn.SiLU, nn.Sigmoid, nn.Tanh, nn.Hardswish\n",
    ")\n",
    "\n",
    "def list_activations(model):\n",
    "    \"\"\"Print every module whose class is in ACT_TYPES.\"\"\"\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, ACT_TYPES):\n",
    "            print(f'{name:<60} {m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.stage0.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage0.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage0.6.tcm.0.act                                  GELU(approximate='none')\n",
      "backbone.stage0.6.tcm.1.act                                  GELU(approximate='none')\n",
      "backbone.stage0.6.tcm.2.act                                  GELU(approximate='none')\n",
      "backbone.stage0.6.tcm.3.act                                  GELU(approximate='none')\n",
      "backbone.stage1.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage1.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage1.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage1.6.2                                          GELU(approximate='none')\n",
      "backbone.stage1.8.tcm.0.act                                  GELU(approximate='none')\n",
      "backbone.stage1.8.tcm.1.act                                  GELU(approximate='none')\n",
      "backbone.stage1.8.tcm.2.act                                  GELU(approximate='none')\n",
      "backbone.stage1.8.tcm.3.act                                  GELU(approximate='none')\n",
      "backbone.stage2.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage2.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage2.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage2.6.2                                          GELU(approximate='none')\n",
      "backbone.stage2.8.tcm.0.act                                  GELU(approximate='none')\n",
      "backbone.stage2.8.tcm.1.act                                  GELU(approximate='none')\n",
      "backbone.stage2.8.tcm.2.act                                  GELU(approximate='none')\n",
      "backbone.stage2.8.tcm.3.act                                  GELU(approximate='none')\n",
      "backbone.stage3.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.6.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.7.2                                          GELU(approximate='none')\n",
      "backbone.stage3.9.tcm.0.act                                  GELU(approximate='none')\n",
      "backbone.stage3.9.tcm.1.act                                  GELU(approximate='none')\n",
      "backbone.stage3.9.tcm.2.act                                  GELU(approximate='none')\n",
      "backbone.stage3.9.tcm.3.act                                  GELU(approximate='none')\n",
      "backbone.stage4.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage4.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage4.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage4.7.tcm.0.act                                  GELU(approximate='none')\n",
      "backbone.stage4.7.tcm.1.act                                  GELU(approximate='none')\n",
      "backbone.stage4.7.tcm.2.act                                  GELU(approximate='none')\n",
      "backbone.stage4.7.tcm.3.act                                  GELU(approximate='none')\n"
     ]
    }
   ],
   "source": [
    "list_activations(original_model)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv1dAs2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Replace a Conv1d with an equivalent Conv2d (H = kernel, W = 1)\n",
    "    so that ONNX shows only Conv2d, which RKNN supports.\n",
    "    \"\"\"\n",
    "    def __init__(self, conv1d: nn.Conv1d):\n",
    "        super().__init__()\n",
    "\n",
    "        k, d, s, g = conv1d.kernel_size[0], conv1d.dilation[0], conv1d.stride[0], conv1d.groups\n",
    "\n",
    "        # --- numeric padding ---\n",
    "        if isinstance(conv1d.padding, str):        # \"same\" or \"valid\"\n",
    "            if conv1d.padding == \"same\":\n",
    "                pad_num = floor(d * (k - 1) / 2)\n",
    "            else:                                  # \"valid\"\n",
    "                pad_num = 0\n",
    "        else:                                      # already a tuple/int\n",
    "            pad_num = conv1d.padding[0]\n",
    "\n",
    "        # Build the Conv2d with weights copied\n",
    "        self.conv2d = nn.Conv2d(\n",
    "            in_channels  = conv1d.in_channels,\n",
    "            out_channels = conv1d.out_channels,\n",
    "            kernel_size  = (k, 1),\n",
    "            stride       = (s, 1),\n",
    "            padding      = (pad_num, 0),\n",
    "            dilation     = (d, 1),\n",
    "            groups       = g,\n",
    "            bias         = conv1d.bias is not None\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # (out, in/groups, k) → (out, in/groups, k, 1)\n",
    "            self.conv2d.weight.copy_(conv1d.weight.unsqueeze(-1))\n",
    "            if conv1d.bias is not None:\n",
    "                self.conv2d.bias.copy_(conv1d.bias)\n",
    "\n",
    "    def forward(self, x):           # x: [B, C, T]\n",
    "        #todo : pay attention to the input shape! AVI APPROVED\n",
    "        return self.conv2d(x.unsqueeze(-1)).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_activation_(module, old_cls=nn.GELU, new_cls=nn.ReLU, **new_kwargs):\n",
    "    \"\"\"\n",
    "    In-place, recursive swap of every instance of `old_cls`\n",
    "    with `new_cls(**new_kwargs)`.\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, old_cls):\n",
    "            setattr(module, name, new_cls(**new_kwargs))\n",
    "        else:\n",
    "            replace_activation_(child, old_cls, new_cls, **new_kwargs)\n",
    "# -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 2) Define a Model Class without MelBanks\n",
    "########################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ReDimNetNoMel(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper around the original ReDimNetWrap that:\n",
    "      - Excludes the 'spec' (MelBanks) module\n",
    "      - Uses 'backbone', 'pool', 'bn', and 'linear'\n",
    "    We expect a precomputed mel spectrogram as input with shape [B, 1, n_mels, time_frames].\n",
    "    \"\"\"\n",
    "    def __init__(self, original_wrap):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Grab references to the submodules we want to keep\n",
    "        self.backbone = original_wrap.backbone\n",
    "        \n",
    "        # fix problem01\n",
    "        # list of (stage, block) indices you already know are problematic\n",
    "        TARGETS = [(0, 6), (1, 8), (2, 8), (3, 9), (4, 7)]\n",
    "        for s_idx, b_idx in TARGETS:\n",
    "            for tcm_idx in range(4):\n",
    "                block = self.backbone.__getattr__(f\"stage{s_idx}\")[b_idx].tcm[tcm_idx]\n",
    "\n",
    "                block.dwconvs[0] = Conv1dAs2d(block.dwconvs[0])\n",
    "                block.pwconv1    = Conv1dAs2d(block.pwconv1)   # 1×1 conv\n",
    "\n",
    "        \n",
    "        # Replace ASTP with RKNN-safe version:\n",
    "        self.pool = original_wrap.pool\n",
    "        self.bn = original_wrap.bn\n",
    "        self.linear = original_wrap.linear\n",
    "        \n",
    "        ## Replace activations in the backbone\n",
    "        replace_activation_(self, old_cls=nn.GELU, new_cls=nn.ReLU, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: shape [B, 1, n_mels, time_frames]\n",
    "        # (1) Pass through the backbone\n",
    "        x = self.backbone(x)    # shape might become [B, channels, frames] or similar\n",
    "        # (2) Pooling\n",
    "        x = self.pool(x)        # ASTP => shape likely [B, embedding_dim]\n",
    "        # (3) BatchNorm\n",
    "        x = self.bn(x)\n",
    "        # (4) Final linear => 192-dim (if that's your embedding size)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of our new model that skips the MelBanks front-end\n",
    "model_no_mel = ReDimNetNoMel(original_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run to test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7365,  1.0759, -0.6940, -1.0579, -0.7059,  1.6571,  1.9979, -2.4022,\n",
       "          2.1213,  0.7834,  1.4141, -0.5012, -2.2235, -0.4847,  0.3751, -0.7104,\n",
       "          1.8739, -1.3768,  3.4070, -3.9223,  1.1872,  0.2878, -0.1493, -0.1966,\n",
       "         -0.1660, -3.9006, -0.7316, -0.3083,  0.2936, -1.8908, -0.1829, -2.8669,\n",
       "          0.9803,  2.2765, -3.1350, -0.7542, -1.2604,  0.2856, -0.9750, -1.3746,\n",
       "         -0.5465, -0.6976,  3.6430, -3.7667, -1.2101,  1.4628,  0.3868,  0.0859,\n",
       "         -2.4778,  1.5116, -3.6321,  1.5293, -1.1151,  0.5311,  1.3703, -0.5612,\n",
       "          1.0931, -1.3428,  0.0884, -3.2513, -0.3971,  0.6107, -2.2148, -0.2863,\n",
       "          0.0272,  0.7508, -3.7184,  1.5076, -0.5306, -0.3696, -1.8484,  0.9330,\n",
       "         -1.8440, -2.7596, -2.2455, -1.4836, -3.7188,  0.7596,  0.6156, -0.3303,\n",
       "         -0.0109,  3.5148,  2.1307, -1.2035, -1.8223,  2.0019,  2.4762,  0.7841,\n",
       "         -0.2911,  0.7248, -0.1079,  1.7438,  0.2696,  1.2449, -2.6904,  0.4372,\n",
       "          1.1173,  0.6585,  1.8102, -4.5490, -5.7734, -0.1605,  1.5966, -0.2581,\n",
       "         -1.7998,  1.7425,  0.6437,  0.7479,  1.2886,  1.4191, -1.7271, -1.2829,\n",
       "          1.0563,  3.2685,  1.9903,  1.9678,  1.9802, -1.8389, -3.8017,  1.8193,\n",
       "         -2.1146, -1.3092,  0.6910,  0.7729,  1.2594,  0.5725,  1.0847,  0.1251,\n",
       "         -0.8150, -0.6684, -0.4142, -1.0505, -0.1359,  1.2552,  0.8999, -1.6038,\n",
       "         -2.7332, -0.3882, -0.3198,  0.4751, -1.8111, -3.0467, -1.2296,  0.1845,\n",
       "          1.3980, -1.1045,  1.4106, -2.0942, -2.1030,  0.9369,  0.3951,  3.0983,\n",
       "          2.3456,  1.1285,  1.2157,  3.5109,  1.3130, -1.1477,  1.0684,  3.7533,\n",
       "          1.4165, -0.9693, -1.3494,  1.3630, -0.6813, -1.4902, -0.0177, -1.5814,\n",
       "         -0.2302,  1.9413,  0.5647,  2.8466, -1.1922, -0.1309,  0.6886,  1.5715,\n",
       "         -1.2448,  3.8784,  0.0255, -0.9900, -2.2618, -0.8931, -1.9445, -2.1078,\n",
       "          0.0714, -0.7948, -2.1696,  1.6048,  0.8185, -2.2136, -0.2604, -1.0517]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mel.eval()  # <- this line is critical!\n",
    "dummy = torch.randn(1, 1, 60, 200)\n",
    "model_no_mel(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP16 check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe in pure FP16? tensor(True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    fp16_net = copy.deepcopy(model_no_mel).half().eval()\n",
    "    ok = torch.isfinite(fp16_net(dummy.half())).all()\n",
    "    print('safe in pure FP16?', ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.stage0.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage0.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage0.6.tcm.0.act                                  ReLU(inplace=True)\n",
      "backbone.stage0.6.tcm.1.act                                  ReLU(inplace=True)\n",
      "backbone.stage0.6.tcm.2.act                                  ReLU(inplace=True)\n",
      "backbone.stage0.6.tcm.3.act                                  ReLU(inplace=True)\n",
      "backbone.stage1.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage1.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage1.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage1.6.2                                          ReLU(inplace=True)\n",
      "backbone.stage1.8.tcm.0.act                                  ReLU(inplace=True)\n",
      "backbone.stage1.8.tcm.1.act                                  ReLU(inplace=True)\n",
      "backbone.stage1.8.tcm.2.act                                  ReLU(inplace=True)\n",
      "backbone.stage1.8.tcm.3.act                                  ReLU(inplace=True)\n",
      "backbone.stage2.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage2.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage2.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage2.6.2                                          ReLU(inplace=True)\n",
      "backbone.stage2.8.tcm.0.act                                  ReLU(inplace=True)\n",
      "backbone.stage2.8.tcm.1.act                                  ReLU(inplace=True)\n",
      "backbone.stage2.8.tcm.2.act                                  ReLU(inplace=True)\n",
      "backbone.stage2.8.tcm.3.act                                  ReLU(inplace=True)\n",
      "backbone.stage3.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.6.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage3.7.2                                          ReLU(inplace=True)\n",
      "backbone.stage3.9.tcm.0.act                                  ReLU(inplace=True)\n",
      "backbone.stage3.9.tcm.1.act                                  ReLU(inplace=True)\n",
      "backbone.stage3.9.tcm.2.act                                  ReLU(inplace=True)\n",
      "backbone.stage3.9.tcm.3.act                                  ReLU(inplace=True)\n",
      "backbone.stage4.3.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage4.4.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage4.5.conv_block.relu                            ReLU(inplace=True)\n",
      "backbone.stage4.7.tcm.0.act                                  ReLU(inplace=True)\n",
      "backbone.stage4.7.tcm.1.act                                  ReLU(inplace=True)\n",
      "backbone.stage4.7.tcm.2.act                                  ReLU(inplace=True)\n",
      "backbone.stage4.7.tcm.3.act                                  ReLU(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "list_activations(model_no_mel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReDimNetNoMel(\n",
       "  (backbone): ReDimNet(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): LayerNorm(C=(10,), data_format=channels_first, eps=1e-06)\n",
       "      (2): to1d()\n",
       "    )\n",
       "    (stage0): Sequential(\n",
       "      (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
       "      (1): to2d(f=60,c=10)\n",
       "      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv1pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv2pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv1pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "          (conv2pw): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 20, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(20,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(19, 1), stride=(1, 1), padding=(9, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(31, 1), stride=(1, 1), padding=(15, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(59, 1), stride=(1, 1), padding=(29, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (v_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (q_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (out_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(20, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): weigth1d(w=(1, 2, 600, 1),sequential=False)\n",
       "      (1): to2d(f=60,c=10)\n",
       "      (2): Conv2d(10, 40, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv2d(40, 20, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=20)\n",
       "        (1): BatchNorm2d(20, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 20, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(20,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(19, 1), stride=(1, 1), padding=(9, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(31, 1), stride=(1, 1), padding=(15, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(59, 1), stride=(1, 1), padding=(29, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (v_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (q_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (out_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(20, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): weigth1d(w=(1, 3, 600, 1),sequential=False)\n",
       "      (1): to2d(f=30,c=20)\n",
       "      (2): Conv2d(20, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv1pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv2pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv1pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv2pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv1pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n",
       "          (conv2pw): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv2d(60, 20, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=20)\n",
       "        (1): BatchNorm2d(20, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 20, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(20,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(19, 1), stride=(1, 1), padding=(9, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(31, 1), stride=(1, 1), padding=(15, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(20, 20, kernel_size=(59, 1), stride=(1, 1), padding=(29, 0), groups=20)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (v_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (q_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (out_proj): Linear(in_features=20, out_features=20, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=20, out_features=20, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(20, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): weigth1d(w=(1, 4, 600, 1),sequential=False)\n",
       "      (1): to2d(f=30,c=20)\n",
       "      (2): Conv2d(20, 80, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv1pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "          (conv2pw): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Conv2d(80, 40, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=40)\n",
       "        (1): BatchNorm2d(40, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (8): to1d()\n",
       "      (9): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 60, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(60,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(19, 1), stride=(1, 1), padding=(9, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(31, 1), stride=(1, 1), padding=(15, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(59, 1), stride=(1, 1), padding=(29, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (v_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (q_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (out_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(60, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): weigth1d(w=(1, 5, 600, 1),sequential=False)\n",
       "      (1): to2d(f=15,c=40)\n",
       "      (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ResBasicBlock(\n",
       "          (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv1pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (conv2pw): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (downsample): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): to1d()\n",
       "      (7): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(600, 60, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(60,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(19, 1), stride=(1, 1), padding=(9, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(31, 1), stride=(1, 1), padding=(15, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1dAs2d(\n",
       "                (conv2d): Conv2d(60, 60, kernel_size=(59, 1), stride=(1, 1), padding=(29, 0), groups=60)\n",
       "              )\n",
       "            )\n",
       "            (norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (pwconv1): Conv1dAs2d(\n",
       "              (conv2d): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (v_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (q_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (out_proj): Linear(in_features=60, out_features=60, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=60, out_features=60, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(60, 600, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (fin_wght1d): weigth1d(w=(1, 6, 600, 1),sequential=False)\n",
       "    (mfa): Identity()\n",
       "    (fin_to2d): Identity()\n",
       "  )\n",
       "  (pool): ASTP(\n",
       "    (linear1): Conv1d(1800, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 600, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=1200, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ReDimNetNoMel                                                [1, 192]                  --\n",
       "├─ReDimNet: 1-1                                              [1, 600, 134]             --\n",
       "│    └─Sequential: 2-1                                       [1, 600, 134]             --\n",
       "│    │    └─Conv2d: 3-1                                      [1, 10, 60, 134]          100\n",
       "│    │    └─LayerNorm: 3-2                                   [1, 10, 60, 134]          20\n",
       "│    │    └─to1d: 3-3                                        [1, 600, 134]             --\n",
       "│    └─Sequential: 2-2                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-4                                    [1, 600, 134]             (1)\n",
       "│    │    └─to2d: 3-5                                        [1, 10, 60, 134]          --\n",
       "│    │    └─Conv2d: 3-6                                      [1, 10, 60, 134]          110\n",
       "│    │    └─ConvBlock2d: 3-7                                 [1, 10, 60, 134]          440\n",
       "│    │    └─ConvBlock2d: 3-8                                 [1, 10, 60, 134]          440\n",
       "│    │    └─to1d: 3-9                                        [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-10                         [1, 600, 134]             31,500\n",
       "│    └─Sequential: 2-3                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-11                                   [1, 600, 134]             1,200\n",
       "│    │    └─to2d: 3-12                                       [1, 10, 60, 134]          --\n",
       "│    │    └─Conv2d: 3-13                                     [1, 40, 30, 134]          840\n",
       "│    │    └─ConvBlock2d: 3-14                                [1, 40, 30, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-15                                [1, 40, 30, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-16                                [1, 40, 30, 134]          4,160\n",
       "│    │    └─Sequential: 3-17                                 [1, 20, 30, 134]          840\n",
       "│    │    └─to1d: 3-18                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-19                         [1, 600, 134]             31,500\n",
       "│    └─Sequential: 2-4                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-20                                   [1, 600, 134]             1,800\n",
       "│    │    └─to2d: 3-21                                       [1, 20, 30, 134]          --\n",
       "│    │    └─Conv2d: 3-22                                     [1, 60, 30, 134]          1,260\n",
       "│    │    └─ConvBlock2d: 3-23                                [1, 60, 30, 134]          8,640\n",
       "│    │    └─ConvBlock2d: 3-24                                [1, 60, 30, 134]          8,640\n",
       "│    │    └─ConvBlock2d: 3-25                                [1, 60, 30, 134]          8,640\n",
       "│    │    └─Sequential: 3-26                                 [1, 20, 30, 134]          1,020\n",
       "│    │    └─to1d: 3-27                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-28                         [1, 600, 134]             31,500\n",
       "│    └─Sequential: 2-5                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-29                                   [1, 600, 134]             2,400\n",
       "│    │    └─to2d: 3-30                                       [1, 20, 30, 134]          --\n",
       "│    │    └─Conv2d: 3-31                                     [1, 80, 15, 134]          3,280\n",
       "│    │    └─ConvBlock2d: 3-32                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─ConvBlock2d: 3-33                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─ConvBlock2d: 3-34                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─ConvBlock2d: 3-35                                [1, 80, 15, 134]          14,720\n",
       "│    │    └─Sequential: 3-36                                 [1, 40, 15, 134]          2,480\n",
       "│    │    └─to1d: 3-37                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-38                         [1, 600, 134]             117,300\n",
       "│    └─Sequential: 2-6                                       [1, 600, 134]             --\n",
       "│    │    └─weigth1d: 3-39                                   [1, 600, 134]             3,000\n",
       "│    │    └─to2d: 3-40                                       [1, 40, 15, 134]          --\n",
       "│    │    └─Conv2d: 3-41                                     [1, 40, 15, 134]          1,640\n",
       "│    │    └─ConvBlock2d: 3-42                                [1, 40, 15, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-43                                [1, 40, 15, 134]          4,160\n",
       "│    │    └─ConvBlock2d: 3-44                                [1, 40, 15, 134]          4,160\n",
       "│    │    └─to1d: 3-45                                       [1, 600, 134]             --\n",
       "│    │    └─TimeContextBlock1d: 3-46                         [1, 600, 134]             117,300\n",
       "│    └─weigth1d: 2-7                                         [1, 600, 134]             3,600\n",
       "│    └─Identity: 2-8                                         [1, 600, 134]             --\n",
       "│    └─Identity: 2-9                                         [1, 600, 134]             --\n",
       "├─ASTP: 1-2                                                  [1, 1200]                 --\n",
       "│    └─Conv1d: 2-10                                          [1, 128, 134]             230,528\n",
       "│    └─Conv1d: 2-11                                          [1, 600, 134]             77,400\n",
       "├─BatchNorm1d: 1-3                                           [1, 1200]                 2,400\n",
       "├─Linear: 1-4                                                [1, 192]                  230,592\n",
       "==============================================================================================================\n",
       "Total params: 1,004,251\n",
       "Trainable params: 1,004,250\n",
       "Non-trainable params: 1\n",
       "Total mult-adds (M): 406.29\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 133.03\n",
       "Params size (MB): 4.02\n",
       "Estimated Total Size (MB): 137.08\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_no_mel, (1, 1, 60, 134))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TORCH SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_inference(wav_path: str):\n",
    "    # (a) Load audio\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)  # shape: [channels, time]\n",
    "    # If stereo, select one channel, or average:\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Resample if needed\n",
    "    target_sample_rate=16000\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # (b) Convert to log-mel\n",
    "    log_mel = myUtils.waveform_to_logmel(waveform)\n",
    "    print('feeding logmel shape:', log_mel.shape)\n",
    "    \n",
    "    # (c) Forward pass\n",
    "    with torch.no_grad():\n",
    "        embedding = model_no_mel(log_mel)  # shape typically [1, 192] or so\n",
    "\n",
    "    print(\"Embedding shape:\", embedding.shape)\n",
    "    #print(\"Embedding:\", embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 60, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 25776])\n",
      "Padding log_mel from 108 to 134 frames\n",
      "feeding logmel shape: torch.Size([1, 1, 60, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 23570])\n",
      "Padding log_mel from 99 to 134 frames\n",
      "feeding logmel shape: torch.Size([1, 1, 60, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 60, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 60, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 28126])\n",
      "Padding log_mel from 118 to 134 frames\n",
      "feeding logmel shape: torch.Size([1, 1, 60, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 60, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "**************************************************************************\n",
      "*************************   compare summary ******************************\n",
      "**************************************************************************\n",
      "====>>>> should be similar:\n",
      "Similarity (robot1 to robot2 ): 0.8750576376914978\n",
      "Similarity (human1 to human1 ): 0.7205746173858643\n",
      "Similarity (human2 to human2 ): 0.5557476282119751\n",
      "====>>>> should be differnet:\n",
      "Similarity (robot to human1  ): 0.42599189281463623\n",
      "Similarity (robot to human2  ): 0.2968902885913849\n",
      "Similarity (human1 to human2 ): 0.36577820777893066\n"
     ]
    }
   ],
   "source": [
    "torch_embedding = test_all_voices(\n",
    "    extract_speaker_embedding_function = torch_inference,\n",
    "    cosine_similarity_function = myUtils.cosine_similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare to baseline\n",
    "\n",
    "* test embedding compare of voice in the currnet model with baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity embde0: 0.725683867931366\n",
      "Similarity embde1: 0.8639224767684937\n",
      "Similarity embde2: 0.7972668409347534\n",
      "Similarity embde3: 0.6831815242767334\n",
      "Similarity embde4: 0.7413924932479858\n",
      "Similarity embde5: 0.7062074542045593\n",
      "Similarity embde6: 0.7143062353134155\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity embde0: {myUtils.cosine_similarity(base_line_embedding['embed0'], torch_embedding['embed0'])}\")\n",
    "print(f\"Similarity embde1: {myUtils.cosine_similarity(base_line_embedding['embed1'], torch_embedding['embed1'])}\")\n",
    "print(f\"Similarity embde2: {myUtils.cosine_similarity(base_line_embedding['embed2'], torch_embedding['embed2'])}\")\n",
    "print(f\"Similarity embde3: {myUtils.cosine_similarity(base_line_embedding['embed3'], torch_embedding['embed3'])}\")\n",
    "print(f\"Similarity embde4: {myUtils.cosine_similarity(base_line_embedding['embed4'], torch_embedding['embed4'])}\")\n",
    "print(f\"Similarity embde5: {myUtils.cosine_similarity(base_line_embedding['embed5'], torch_embedding['embed5'])}\")\n",
    "print(f\"Similarity embde6: {myUtils.cosine_similarity(base_line_embedding['embed6'], torch_embedding['embed6'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to ReDimNet_no_mel.onnx\n",
      "-rw-rw-r-- 1 vlad vlad 4.1M Jun 24 12:13 ReDimNet_no_mel.onnx\n"
     ]
    }
   ],
   "source": [
    "myUtils.export_to_onnx(model_no_mel,onnx_path = \"ReDimNet_no_mel.onnx\")\n",
    "!ls -lah ReDimNet_no_mel.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ReDimNet_no_mel.onnx to half precision and saved as ReDimNet_no_mel_fp16.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.605193857299268e-45 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.2503155177867598e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.4816506287478153e-14 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.2374582096875482e-17 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.89484008880936e-09 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 7.13836811883084e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.0086018242816408e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.0000000116860974e-07 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n"
     ]
    }
   ],
   "source": [
    "myUtils.restore_in_half_precision('ReDimNet_no_mel.onnx','ReDimNet_no_mel_fp16.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_path = \"ReDimNet_no_mel.onnx\"\n",
    "onnx_path = \"ReDimNet_no_mel_fp16.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_onnx(wav_path):\n",
    "    \"\"\"\n",
    "    Loads an audio file, converts to log-mel, and runs inference\n",
    "    in an ONNX session. Returns the embedding as a NumPy array.\n",
    "    \"\"\"\n",
    "    print(\"===================================================\")\n",
    "    print(\"===========   run_inference_onnx   ================\")\n",
    "    print(\"===================================================\")\n",
    "    #######################################\n",
    "    # 1) Load your ONNX model\n",
    "    #######################################\n",
    "    # (Optional) onnx.checker to confirm it’s valid\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(f\"Loaded and checked ONNX model from: {onnx_path}\")\n",
    "\n",
    "    # Create an inference session\n",
    "    session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "    # Usually we retrieve the first input & output name\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "    #######################################\n",
    "    # 2) Load audio, get log-mel\n",
    "    #######################################\n",
    "    print(\"loading audio from:\", wav_path)\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    print(f\"...Waveform rate {sample_rate}  ; shape : {waveform.shape}\")\n",
    "\n",
    "    \n",
    "    # If multi-channel, downmix:\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        \n",
    "    # Resample if needed\n",
    "    target_sample_rate=16000\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "        # save resampled waveform to files with suffix \"_resampled_16.wav\"\n",
    "        # torchaudio.save(wav_path.replace(\".wav\", \"_resampled_16.wav\"), waveform, target_sample_rate)\n",
    "\n",
    "    log_mel =  myUtils.waveform_to_logmel(waveform)\n",
    "    \n",
    "    #######################################\n",
    "    # 3) ONNX Inference\n",
    "    #######################################\n",
    "    # Convert to NumPy for ONNX runtime\n",
    "    log_mel_np = log_mel.cpu().numpy()\n",
    "    \n",
    "    ## save log_mel_np to file with suffix \"_logmel.npy\" to check later\n",
    "    print(\"logmelshape : \", log_mel_np.shape)\n",
    "    log_mel_fp16 = log_mel_np.astype(np.float16)  # → half precision\n",
    "    orig_name = os.path.splitext(os.path.basename(wav_path))[0]\n",
    "    folder = os.path.dirname(wav_path)\n",
    "    out_path = os.path.join(folder, f\"logmel_{orig_name}.npy\")\n",
    "    np.save(out_path, log_mel_fp16)\n",
    "    \n",
    "    # Run inference\n",
    "    outputs = session.run([output_name], {input_name: log_mel_np})\n",
    "    # outputs is a list; typically we want the first item\n",
    "    embedding = outputs[0]  # shape is [1, embedding_dim]\n",
    "\n",
    "    # print(\"Embedding[10]: \", embedding[0:10])  # Print the 10th element of the embedding\n",
    "    print(\"Embedding shape:\", embedding.shape)\n",
    "    # print(\"Embedding data:\\n\", embedding)\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel_fp16.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB0/utils/../audio/test000.wav\n",
      "...Waveform rate 16000  ; shape : torch.Size([1, 293699])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 60, 134)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-06-24 12:13:28.071918697 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.078115702 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.286528107 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.292117512 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel_fp16.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB0/utils/../audio/testRob1.wav\n",
      "...Waveform rate 22050  ; shape : torch.Size([1, 35522])\n",
      "Input waveform shape: torch.Size([1, 25776])\n",
      "Padding log_mel from 108 to 134 frames\n",
      "logmelshape :  (1, 1, 60, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel_fp16.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB0/utils/../audio/testRob2.wav\n",
      "...Waveform rate 22050  ; shape : torch.Size([1, 32482])\n",
      "Input waveform shape: torch.Size([1, 23570])\n",
      "Padding log_mel from 99 to 134 frames\n",
      "logmelshape :  (1, 1, 60, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel_fp16.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-06-24 12:13:28.455956868 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.461540538 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.626410279 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.631933584 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading audio from: /data/proj/voice/redimnet/wrkB0/utils/../audio/test_human1_1.wav\n",
      "...Waveform rate 16000  ; shape : torch.Size([1, 65867])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 60, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel_fp16.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB0/utils/../audio/test_human1_2.wav\n",
      "...Waveform rate 16000  ; shape : torch.Size([1, 101189])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 60, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel_fp16.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-06-24 12:13:28.811456657 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.817080001 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.976920229 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:28.983394304 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading audio from: /data/proj/voice/redimnet/wrkB0/utils/../audio/test_human2_1.wav\n",
      "...Waveform rate 48000  ; shape : torch.Size([1, 84376])\n",
      "Input waveform shape: torch.Size([1, 28126])\n",
      "Padding log_mel from 118 to 134 frames\n",
      "logmelshape :  (1, 1, 60, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel_fp16.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB0/utils/../audio/test_human2_2.wav\n",
      "...Waveform rate 48000  ; shape : torch.Size([1, 159256])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 60, 134)\n",
      "Embedding shape: (1, 192)\n",
      "**************************************************************************\n",
      "*************************   compare summary ******************************\n",
      "**************************************************************************\n",
      "====>>>> should be similar:\n",
      "Similarity (robot1 to robot2 ): 0.8749251961708069\n",
      "Similarity (human1 to human1 ): 0.7207341194152832\n",
      "Similarity (human2 to human2 ): 0.5557355880737305\n",
      "====>>>> should be differnet:\n",
      "Similarity (robot to human1  ): 0.4260510504245758\n",
      "Similarity (robot to human2  ): 0.2962152063846588\n",
      "Similarity (human1 to human2 ): 0.3661928176879883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-06-24 12:13:29.149022350 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n",
      "\u001b[0;93m2025-06-24 12:13:29.154751947 [W:onnxruntime:, constant_folding.cc:268 ApplyImpl] Could not find a CPU kernel and hence can't constant fold Sub node '/pool/Sub_1'\u001b[m\n"
     ]
    }
   ],
   "source": [
    "onnx_embedding = test_all_voices(\n",
    "    extract_speaker_embedding_function = inference_onnx,\n",
    "    cosine_similarity_function = myUtils.cosine_similarity_numpys,\n",
    "    save_embeddings=True,  # Save embeddings to files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare onnx with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity embde0: 0.9999975562095642\n",
      "Similarity embde1: 0.9999975562095642\n",
      "Similarity embde2: 0.999997615814209\n",
      "Similarity embde3: 0.9999982118606567\n",
      "Similarity embde4: 0.9999983906745911\n",
      "Similarity embde5: 0.9999959468841553\n",
      "Similarity embde6: 0.9999971389770508\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity embde0: {myUtils.cosine_similarity_numpys(torch_embedding['embed0'], onnx_embedding['embed0'])}\")\n",
    "print(f\"Similarity embde1: {myUtils.cosine_similarity_numpys(torch_embedding['embed1'], onnx_embedding['embed1'])}\")\n",
    "print(f\"Similarity embde2: {myUtils.cosine_similarity_numpys(torch_embedding['embed2'], onnx_embedding['embed2'])}\")\n",
    "print(f\"Similarity embde3: {myUtils.cosine_similarity_numpys(torch_embedding['embed3'], onnx_embedding['embed3'])}\")\n",
    "print(f\"Similarity embde4: {myUtils.cosine_similarity_numpys(torch_embedding['embed4'], onnx_embedding['embed4'])}\")\n",
    "print(f\"Similarity embde5: {myUtils.cosine_similarity_numpys(torch_embedding['embed5'], onnx_embedding['embed5'])}\")\n",
    "print(f\"Similarity embde6: {myUtils.cosine_similarity_numpys(torch_embedding['embed6'], onnx_embedding['embed6'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare onnx with base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity embde0: 0.7255515456199646\n",
      "Similarity embde1: 0.863834023475647\n",
      "Similarity embde2: 0.7971532940864563\n",
      "Similarity embde3: 0.6831507086753845\n",
      "Similarity embde4: 0.7414388656616211\n",
      "Similarity embde5: 0.7058244943618774\n",
      "Similarity embde6: 0.7139862775802612\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity embde0: {myUtils.cosine_similarity_numpys(base_line_embedding['embed0'], onnx_embedding['embed0'])}\")\n",
    "print(f\"Similarity embde1: {myUtils.cosine_similarity_numpys(base_line_embedding['embed1'], onnx_embedding['embed1'])}\")\n",
    "print(f\"Similarity embde2: {myUtils.cosine_similarity_numpys(base_line_embedding['embed2'], onnx_embedding['embed2'])}\")\n",
    "print(f\"Similarity embde3: {myUtils.cosine_similarity_numpys(base_line_embedding['embed3'], onnx_embedding['embed3'])}\")\n",
    "print(f\"Similarity embde4: {myUtils.cosine_similarity_numpys(base_line_embedding['embed4'], onnx_embedding['embed4'])}\")\n",
    "print(f\"Similarity embde5: {myUtils.cosine_similarity_numpys(base_line_embedding['embed5'], onnx_embedding['embed5'])}\")\n",
    "print(f\"Similarity embde6: {myUtils.cosine_similarity_numpys(base_line_embedding['embed6'], onnx_embedding['embed6'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cal fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# # Directory for calibration inputs\n",
    "# os.makedirs(\"calib_npy\", exist_ok=True)\n",
    "\n",
    "# # Create 100 dummy log-mel tensors\n",
    "# for i in range(10):\n",
    "#     log_mel = torch.randn(1, 1, 60, 134).numpy().astype(np.float16)\n",
    "#     np.save(f\"calib_npy/sample_{i}.npy\", log_mel)\n",
    "\n",
    "# # Write dataset.txt listing all paths\n",
    "# with open(\"dataset.txt\", \"w\") as f:\n",
    "#     for i in range(10):\n",
    "#         f.write(f\"calib_npy/sample_{i}.npy\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converts\n",
    "\n",
    "```\n",
    "python convert.py \\\n",
    "       ../wrkB0/ReDimNet_no_mel_fp16.onnx rk3588 fp ReDimNet_no_mel.rknn \\\n",
    "       ../wrkB0/audio/logmel_testRob1.npy  ../wrkB0/audio/embedding_testRob1.torch\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvoice_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
