{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Base line for REFERENCE MODEL \n",
    "\n",
    "===============================================================\n",
    "\n",
    "* load the model\n",
    "* extract embeddings \n",
    "* test some voices to set baseline\n",
    "\n",
    "==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "## our utils\n",
    "from utils.common_import import *\n",
    "from utils.test_all_voices import *\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* config the starting point model and get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /data/proj/voice/redimnet/models/IDRnD_ReDimNet_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/redimnet/models/IDRnD_ReDimNet_master\n",
      "load_res : <All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ReDimNetWrap(\n",
       "  (backbone): ReDimNet(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): LayerNorm(C=(16,), data_format=channels_first, eps=1e-06)\n",
       "      (2): to1d()\n",
       "    )\n",
       "    (stage0): Sequential(\n",
       "      (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=16)\n",
       "      (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
       "          )\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
       "          )\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): weigth1d(w=(1, 2, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=16)\n",
       "      (2): Conv2d(16, 32, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): weigth1d(w=(1, 3, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=32)\n",
       "      (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): to1d()\n",
       "      (7): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): weigth1d(w=(1, 4, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=32)\n",
       "      (2): Conv2d(32, 96, kernel_size=(3, 1), stride=(3, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): weigth1d(w=(1, 5, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=12,c=96)\n",
       "      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage5): Sequential(\n",
       "      (0): weigth1d(w=(1, 6, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=12,c=96)\n",
       "      (2): Conv2d(96, 192, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(288,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(7,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(19,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(31,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(59,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (v_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (q_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (out_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(288, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (fin_wght1d): weigth1d(w=(1, 7, 1152, 1),sequential=False)\n",
       "    (mfa): Identity()\n",
       "    (fin_to2d): Identity()\n",
       "  )\n",
       "  (spec): MelBanks(\n",
       "    (torchfbank): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): PreEmphasis()\n",
       "      (2): MelSpectrogram(\n",
       "        (spectrogram): Spectrogram()\n",
       "        (mel_scale): MelScale()\n",
       "      )\n",
       "    )\n",
       "    (specaug): Identity()\n",
       "  )\n",
       "  (pool): ASTP(\n",
       "    (linear1): Conv1d(3456, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1152, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=2304, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_orig_model_B0():\n",
    "\n",
    "    model_name='b2'\n",
    "    # train_type='ft_lm'\n",
    "    train_type='ptn'\n",
    "    dataset='vox2'\n",
    "    \n",
    "    torch.hub.set_dir('/data/proj/voice/redimnet/models')\n",
    "\n",
    "    model = torch.hub.load('IDRnD/ReDimNet', 'ReDimNet', \n",
    "                        model_name=model_name, \n",
    "                        train_type=train_type, \n",
    "                        dataset=dataset)\n",
    "    \n",
    "    return model\n",
    "\n",
    "original_model = load_orig_model_B0()\n",
    "original_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/redimnet/models/IDRnD_ReDimNet_master/redimnet/layers/features.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ReDimNetWrap                                                 [1, 192]                  --\n",
       "├─MelBanks: 1-1                                              [1, 72, 134]              --\n",
       "│    └─Sequential: 2-1                                       [1, 72, 134]              --\n",
       "│    │    └─Identity: 3-1                                    [1, 32000]                --\n",
       "│    │    └─PreEmphasis: 3-2                                 [1, 32000]                --\n",
       "│    │    └─MelSpectrogram: 3-3                              [1, 72, 134]              --\n",
       "├─ReDimNet: 1-2                                              [1, 1152, 134]            --\n",
       "│    └─Sequential: 2-2                                       [1, 1152, 134]            --\n",
       "│    │    └─Conv2d: 3-4                                      [1, 16, 72, 134]          160\n",
       "│    │    └─LayerNorm: 3-5                                   [1, 16, 72, 134]          32\n",
       "│    │    └─to1d: 3-6                                        [1, 1152, 134]            --\n",
       "│    └─Sequential: 2-3                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-7                                    [1, 1152, 134]            (1)\n",
       "│    │    └─to2d: 3-8                                        [1, 16, 72, 134]          --\n",
       "│    │    └─Conv2d: 3-9                                      [1, 16, 72, 134]          272\n",
       "│    │    └─ConvBlock2d: 3-10                                [1, 16, 72, 134]          896\n",
       "│    │    └─ConvBlock2d: 3-11                                [1, 16, 72, 134]          896\n",
       "│    │    └─to1d: 3-12                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-13                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-4                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-14                                   [1, 1152, 134]            2,304\n",
       "│    │    └─to2d: 3-15                                       [1, 16, 72, 134]          --\n",
       "│    │    └─Conv2d: 3-16                                     [1, 32, 36, 134]          1,056\n",
       "│    │    └─ConvBlock2d: 3-17                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-18                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─to1d: 3-19                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-20                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-5                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-21                                   [1, 1152, 134]            3,456\n",
       "│    │    └─to2d: 3-22                                       [1, 32, 36, 134]          --\n",
       "│    │    └─Conv2d: 3-23                                     [1, 32, 36, 134]          1,056\n",
       "│    │    └─ConvBlock2d: 3-24                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-25                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─ConvBlock2d: 3-26                                [1, 32, 36, 134]          2,304\n",
       "│    │    └─to1d: 3-27                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-28                         [1, 1152, 134]            328,416\n",
       "│    └─Sequential: 2-6                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-29                                   [1, 1152, 134]            4,608\n",
       "│    │    └─to2d: 3-30                                       [1, 32, 36, 134]          --\n",
       "│    │    └─Conv2d: 3-31                                     [1, 96, 12, 134]          9,312\n",
       "│    │    └─ConvBlock2d: 3-32                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-33                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-34                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-35                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─to1d: 3-36                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-37                         [1, 1152, 134]            561,168\n",
       "│    └─Sequential: 2-7                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-38                                   [1, 1152, 134]            5,760\n",
       "│    │    └─to2d: 3-39                                       [1, 96, 12, 134]          --\n",
       "│    │    └─Conv2d: 3-40                                     [1, 96, 12, 134]          9,312\n",
       "│    │    └─ConvBlock2d: 3-41                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-42                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-43                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─ConvBlock2d: 3-44                                [1, 96, 12, 134]          13,056\n",
       "│    │    └─to1d: 3-45                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-46                         [1, 1152, 134]            561,168\n",
       "│    └─Sequential: 2-8                                       [1, 1152, 134]            --\n",
       "│    │    └─weigth1d: 3-47                                   [1, 1152, 134]            6,912\n",
       "│    │    └─to2d: 3-48                                       [1, 96, 12, 134]          --\n",
       "│    │    └─Conv2d: 3-49                                     [1, 192, 6, 134]          37,056\n",
       "│    │    └─ConvBlock2d: 3-50                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-51                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-52                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─ConvBlock2d: 3-53                                [1, 192, 6, 134]          44,544\n",
       "│    │    └─to1d: 3-54                                       [1, 1152, 134]            --\n",
       "│    │    └─TimeContextBlock1d: 3-55                         [1, 1152, 134]            1,535,904\n",
       "│    └─weigth1d: 2-9                                         [1, 1152, 134]            8,064\n",
       "│    └─Identity: 2-10                                        [1, 1152, 134]            --\n",
       "│    └─Identity: 2-11                                        [1, 1152, 134]            --\n",
       "├─ASTP: 1-3                                                  [1, 2304]                 --\n",
       "│    └─Conv1d: 2-12                                          [1, 128, 134]             442,496\n",
       "│    └─Conv1d: 2-13                                          [1, 1152, 134]            148,608\n",
       "├─BatchNorm1d: 1-4                                           [1, 2304]                 4,608\n",
       "├─Linear: 1-5                                                [1, 192]                  442,560\n",
       "==============================================================================================================\n",
       "Total params: 5,067,057\n",
       "Trainable params: 5,067,056\n",
       "Non-trainable params: 1\n",
       "Total mult-adds (M): 896.54\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 118.09\n",
       "Params size (MB): 20.27\n",
       "Estimated Total Size (MB): 138.49\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(original_model, input_size=(1, 32000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALC FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speaker_embedding(wav_path, target_sample_rate=16000, target_length=32000):\n",
    "    \"\"\"\n",
    "    Extracts a speaker embedding from a given WAV file using the ReDimNet model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The ReDimNet model\n",
    "    - wav_path: Path to the WAV file\n",
    "    - target_sample_rate: Sample rate the model expects (default: 16kHz)\n",
    "    - target_length: Number of samples the model expects (default: 32000 = 2 sec @ 16kHz)\n",
    "    \n",
    "    Returns:\n",
    "    - speaker_embedding: The extracted speaker embedding as a PyTorch tensor\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    \n",
    "    # Convert to mono if needed\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # Resample if needed\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    # Ensure the waveform has exactly `target_length` samples\n",
    "    if waveform.shape[1] < target_length:\n",
    "        # Pad with zeros if too short\n",
    "        pad_size = target_length - waveform.shape[1]\n",
    "        waveform = F.pad(waveform, (0, pad_size))\n",
    "        print(f\"Padding waveform to {target_length} samples.\")\n",
    "    else:\n",
    "        # Trim if too long\n",
    "        waveform = waveform[:, :target_length]\n",
    "        print(f\"Trimming waveform to {target_length} samples.\")\n",
    "    \n",
    "    # Ensure correct shape (batch_size, num_samples)\n",
    "    print(f\"waveform Sample Shape: {waveform.shape} ; type : {type(waveform)}\")\n",
    "    \n",
    "    # Extract speaker embedding\n",
    "    with torch.no_grad():\n",
    "        speaker_embedding = original_model(waveform)\n",
    "        \n",
    "    print(f\"Speaker Embedding Shape: {speaker_embedding.shape} ; type : {type(speaker_embedding)}\")  # Expected: (1, embedding_dim)\n",
    "    \n",
    "    return speaker_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity between two embeddings\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1, embedding2).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set BASE LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "Padding waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "Padding waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "Trimming waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "Trimming waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "Padding waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "Trimming waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "**************************************************************************\n",
      "*************************   compare summary ******************************\n",
      "**************************************************************************\n",
      "====>>>> should be similar:\n",
      "Similarity (robot1 to robot2 ): 0.7134692668914795\n",
      "Similarity (human1 to human1 ): 0.5713654160499573\n",
      "Similarity (human2 to human2 ): 0.40392372012138367\n",
      "====>>>> should be differnet:\n",
      "Similarity (robot to human1  ): 0.05458071455359459\n",
      "Similarity (robot to human2  ): -0.08581750094890594\n",
      "Similarity (human1 to human2 ): 0.044351719319820404\n"
     ]
    }
   ],
   "source": [
    "base_line_embedding = test_all_voices(\n",
    "    extract_speaker_embedding_function = extract_speaker_embedding,\n",
    "    cosine_similarity_function = cosine_similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test input len\n",
    "\n",
    "* test how target file len is affecting the output embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming waveform to 32000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 32000]) ; type : <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/redimnet/models/IDRnD_ReDimNet_master/redimnet/layers/features.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n",
      "Trimming waveform to 16000 samples.\n",
      "waveform Sample Shape: torch.Size([1, 16000]) ; type : <class 'torch.Tensor'>\n",
      "Speaker Embedding Shape: torch.Size([1, 192]) ; type : <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embd_len1 = extract_speaker_embedding(wav_path='./audio/test000.wav',target_sample_rate=16000, target_length=32000)\n",
    "embd_len2 = extract_speaker_embedding(wav_path='./audio/test000.wav',target_sample_rate=16000, target_length=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33534541726112366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embd_len1, embd_len2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
