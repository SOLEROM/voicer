{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define basic model with noMel\n",
    "\n",
    "\n",
    "===============================================================\n",
    "\n",
    "* build new noMel model based on base line\n",
    "* run voice through the model and compare with baseline\n",
    "* store to onnx (full32) and compare torch with onnx; \n",
    "\n",
    "==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "## our utils\n",
    "from utils.common_import import *\n",
    "from utils.test_all_voices import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load related modules (import once by running ref notebooks and hide outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display          \n",
    "import my_utils as myUtils\n",
    "from play1_setBase_line_B2 import original_model,base_line_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see MelSpectrogram inside the model ; lets take it outside the model;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone => ReDimNet(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): LayerNorm(C=(16,), data_format=channels_first, eps=1e-06)\n",
      "    (2): to1d()\n",
      "  )\n",
      "  (stage0): Sequential(\n",
      "    (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
      "    (1): to2d(f=72,c=16)\n",
      "    (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
      "        )\n",
      "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
      "        )\n",
      "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): to1d()\n",
      "    (6): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage1): Sequential(\n",
      "    (0): weigth1d(w=(1, 2, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=72,c=16)\n",
      "    (2): Conv2d(16, 32, kernel_size=(2, 1), stride=(2, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): to1d()\n",
      "    (6): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (0): weigth1d(w=(1, 3, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=36,c=32)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
      "        )\n",
      "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): to1d()\n",
      "    (7): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
      "          )\n",
      "          (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): weigth1d(w=(1, 4, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=36,c=32)\n",
      "    (2): Conv2d(32, 96, kernel_size=(3, 1), stride=(3, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): to1d()\n",
      "    (8): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): weigth1d(w=(1, 5, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=12,c=96)\n",
      "    (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
      "        )\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): to1d()\n",
      "    (8): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
      "          )\n",
      "          (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (stage5): Sequential(\n",
      "    (0): weigth1d(w=(1, 6, 1152, 1),sequential=False)\n",
      "    (1): to2d(f=12,c=96)\n",
      "    (2): Conv2d(96, 192, kernel_size=(2, 1), stride=(2, 1))\n",
      "    (3): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): ConvBlock2d(\n",
      "      (conv_block): ConvNeXtLikeBlock(\n",
      "        (dwconvs): ModuleList(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
      "        )\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): to1d()\n",
      "    (8): TimeContextBlock1d(\n",
      "      (red_dim_conv): Sequential(\n",
      "        (0): Conv1d(1152, 288, kernel_size=(1,), stride=(1,))\n",
      "        (1): LayerNorm(C=(288,), data_format=channels_first, eps=1e-06)\n",
      "      )\n",
      "      (tcm): Sequential(\n",
      "        (0): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(7,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(19,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(31,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): ConvNeXtLikeBlock(\n",
      "          (dwconvs): ModuleList(\n",
      "            (0): Conv1d(288, 288, kernel_size=(59,), stride=(1,), padding=same, groups=288)\n",
      "          )\n",
      "          (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (k_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (v_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (q_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (out_proj): Linear(in_features=288, out_features=288, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
      "          (feed_forward): FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (intermediate_act_fn): NewGELUActivation()\n",
      "            (output_dense): Linear(in_features=288, out_features=288, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_dim_conv): Conv1d(288, 1152, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (fin_wght1d): weigth1d(w=(1, 7, 1152, 1),sequential=False)\n",
      "  (mfa): Identity()\n",
      "  (fin_to2d): Identity()\n",
      ")\n",
      "spec => MelBanks(\n",
      "  (torchfbank): Sequential(\n",
      "    (0): Identity()\n",
      "    (1): PreEmphasis()\n",
      "    (2): MelSpectrogram(\n",
      "      (spectrogram): Spectrogram()\n",
      "      (mel_scale): MelScale()\n",
      "    )\n",
      "  )\n",
      "  (specaug): Identity()\n",
      ")\n",
      "pool => ASTP(\n",
      "  (linear1): Conv1d(3456, 128, kernel_size=(1,), stride=(1,))\n",
      "  (linear2): Conv1d(128, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "bn => BatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "linear => Linear(in_features=2304, out_features=192, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in original_model.named_children():\n",
    "    print(name, \"=>\", module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* default MODEL with MelSpectrogram outside the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReDimNetNoMel(\n",
       "  (backbone): ReDimNet(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): LayerNorm(C=(16,), data_format=channels_first, eps=1e-06)\n",
       "      (2): to1d()\n",
       "    )\n",
       "    (stage0): Sequential(\n",
       "      (0): weigth1d(w=(1, 1, 1, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=16)\n",
       "      (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
       "          )\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=4)\n",
       "          )\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): weigth1d(w=(1, 2, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=72,c=16)\n",
       "      (2): Conv2d(16, 32, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): to1d()\n",
       "      (6): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): weigth1d(w=(1, 3, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=32)\n",
       "      (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=8)\n",
       "          )\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): to1d()\n",
       "      (7): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 96, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(96,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(19,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(31,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(96, 96, kernel_size=(59,), stride=(1,), padding=same, groups=96)\n",
       "            )\n",
       "            (norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (v_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (q_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (out_proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(96, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): weigth1d(w=(1, 4, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=36,c=32)\n",
       "      (2): Conv2d(32, 96, kernel_size=(3, 1), stride=(3, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): weigth1d(w=(1, 5, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=12,c=96)\n",
       "      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=24)\n",
       "          )\n",
       "          (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 144, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(144,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(7,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(19,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(31,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(144, 144, kernel_size=(59,), stride=(1,), padding=same, groups=144)\n",
       "            )\n",
       "            (norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(144, 144, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (v_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (q_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (out_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(144, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (stage5): Sequential(\n",
       "      (0): weigth1d(w=(1, 6, 1152, 1),sequential=False)\n",
       "      (1): to2d(f=12,c=96)\n",
       "      (2): Conv2d(96, 192, kernel_size=(2, 1), stride=(2, 1))\n",
       "      (3): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock2d(\n",
       "        (conv_block): ConvNeXtLikeBlock(\n",
       "          (dwconvs): ModuleList(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=48)\n",
       "          )\n",
       "          (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): to1d()\n",
       "      (8): TimeContextBlock1d(\n",
       "        (red_dim_conv): Sequential(\n",
       "          (0): Conv1d(1152, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): LayerNorm(C=(288,), data_format=channels_first, eps=1e-06)\n",
       "        )\n",
       "        (tcm): Sequential(\n",
       "          (0): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(7,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(19,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(31,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): ConvNeXtLikeBlock(\n",
       "            (dwconvs): ModuleList(\n",
       "              (0): Conv1d(288, 288, kernel_size=(59,), stride=(1,), padding=same, groups=288)\n",
       "            )\n",
       "            (norm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (attention): MultiHeadAttention(\n",
       "              (k_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (v_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (q_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (out_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "            )\n",
       "            (layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (intermediate_act_fn): NewGELUActivation()\n",
       "              (output_dense): Linear(in_features=288, out_features=288, bias=True)\n",
       "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (exp_dim_conv): Conv1d(288, 1152, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (fin_wght1d): weigth1d(w=(1, 7, 1152, 1),sequential=False)\n",
       "    (mfa): Identity()\n",
       "    (fin_to2d): Identity()\n",
       "  )\n",
       "  (pool): ASTP(\n",
       "    (linear1): Conv1d(3456, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1152, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=2304, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# 2) Define a Model Class without MelBanks\n",
    "########################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ReDimNetNoMel(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper around the original ReDimNetWrap that:\n",
    "      - Excludes the 'spec' (MelBanks) module\n",
    "      - Uses 'backbone', 'pool', 'bn', and 'linear'\n",
    "    We expect a precomputed mel spectrogram as input with shape [B, 1, n_mels, time_frames].\n",
    "    \"\"\"\n",
    "    def __init__(self, original_wrap):\n",
    "        super().__init__()\n",
    "        # Grab references to the submodules we want to keep\n",
    "        self.backbone = original_wrap.backbone\n",
    "        self.pool = original_wrap.pool\n",
    "        self.bn = original_wrap.bn\n",
    "        self.linear = original_wrap.linear\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: shape [B, 1, n_mels, time_frames]\n",
    "        # (1) Pass through the backbone\n",
    "        x = self.backbone(x)    # shape might become [B, channels, frames] or similar\n",
    "        # (2) Pooling\n",
    "        x = self.pool(x)        # ASTP => shape likely [B, embedding_dim]\n",
    "        # (3) BatchNorm\n",
    "        x = self.bn(x)\n",
    "        # (4) Final linear => 192-dim (if that's your embedding size)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of our new model that skips the MelBanks front-end\n",
    "model_no_mel = ReDimNetNoMel(original_model)\n",
    "model_no_mel.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TORCH SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_inference(wav_path: str):\n",
    "    # (a) Load audio\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)  # shape: [channels, time]\n",
    "    # If stereo, select one channel, or average:\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    target_sample_rate = 16000  # Force to 16kHz as per model requirements\n",
    "    # Resample if needed\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # (b) Convert to log-mel\n",
    "    log_mel = myUtils.waveform_to_logmel(waveform)\n",
    "    print('feeding logmel shape:', log_mel.shape)\n",
    "\n",
    "    # (c) Forward pass\n",
    "    with torch.no_grad():\n",
    "        embedding = model_no_mel(log_mel)  # shape typically [1, 192] or so\n",
    "\n",
    "    print(\"Embedding shape:\", embedding.shape)\n",
    "    #print(\"Embedding:\", embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 72, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 25776])\n",
      "Padding log_mel from 108 to 134 frames\n",
      "feeding logmel shape: torch.Size([1, 1, 72, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 23570])\n",
      "Padding log_mel from 99 to 134 frames\n",
      "feeding logmel shape: torch.Size([1, 1, 72, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 72, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 72, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 28126])\n",
      "Padding log_mel from 118 to 134 frames\n",
      "feeding logmel shape: torch.Size([1, 1, 72, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "feeding logmel shape: torch.Size([1, 1, 72, 134])\n",
      "Embedding shape: torch.Size([1, 192])\n",
      "**************************************************************************\n",
      "*************************   compare summary ******************************\n",
      "**************************************************************************\n",
      "====>>>> should be similar:\n",
      "Similarity (robot1 to robot2 ): 0.669571042060852\n",
      "Similarity (human1 to human1 ): 0.5778868198394775\n",
      "Similarity (human2 to human2 ): 0.39133650064468384\n",
      "====>>>> should be differnet:\n",
      "Similarity (robot to human1  ): 0.03835270181298256\n",
      "Similarity (robot to human2  ): -0.07448571920394897\n",
      "Similarity (human1 to human2 ): 0.0468384213745594\n"
     ]
    }
   ],
   "source": [
    "torch_embedding = test_all_voices(\n",
    "    extract_speaker_embedding_function = torch_inference,\n",
    "    cosine_similarity_function = myUtils.cosine_similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare to baseline\n",
    "\n",
    "* test embedding compare of voice in the currnet model with baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity embde0: 0.9999998807907104\n",
      "Similarity embde1: 0.9944316148757935\n",
      "Similarity embde2: 0.9896695613861084\n",
      "Similarity embde3: 0.9992930293083191\n",
      "Similarity embde4: 0.9998515844345093\n",
      "Similarity embde5: 0.9976835250854492\n",
      "Similarity embde6: 0.9999997615814209\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity embde0: {myUtils.cosine_similarity(base_line_embedding['embed0'], torch_embedding['embed0'])}\")\n",
    "print(f\"Similarity embde1: {myUtils.cosine_similarity(base_line_embedding['embed1'], torch_embedding['embed1'])}\")\n",
    "print(f\"Similarity embde2: {myUtils.cosine_similarity(base_line_embedding['embed2'], torch_embedding['embed2'])}\")\n",
    "print(f\"Similarity embde3: {myUtils.cosine_similarity(base_line_embedding['embed3'], torch_embedding['embed3'])}\")\n",
    "print(f\"Similarity embde4: {myUtils.cosine_similarity(base_line_embedding['embed4'], torch_embedding['embed4'])}\")\n",
    "print(f\"Similarity embde5: {myUtils.cosine_similarity(base_line_embedding['embed5'], torch_embedding['embed5'])}\")\n",
    "print(f\"Similarity embde6: {myUtils.cosine_similarity(base_line_embedding['embed6'], torch_embedding['embed6'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported NHWC model to ReDimNet_no_mel_nhwc.onnx\n",
      "Exported to ReDimNet_no_mel.onnx\n",
      "-rw-rw-r-- 1 vlad vlad 20M Jul  6 06:26 ReDimNet_no_mel.onnx\n"
     ]
    }
   ],
   "source": [
    "myUtils.export_to_onnx(model_no_mel,onnx_path = \"ReDimNet_no_mel.onnx\")\n",
    "!ls -lah ReDimNet_no_mel.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp16_net = copy.deepcopy(model_no_mel).half().eval()\n",
    "# fp16_dummy = dummy_input = torch.randn(1, 1, 60, 134).half()\n",
    "\n",
    "# #  fixed-length segments \n",
    "# torch.onnx.export(\n",
    "#    fp16_net,\n",
    "#    fp16_dummy,\n",
    "#    \"ReDimNet_no_mel_half.onnx\",\n",
    "#    input_names=[\"log_mel\"],\n",
    "#    output_names=[\"embedding\"],\n",
    "#    opset_version=13\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's .half() is unreliable for full model precision control in ONNX. Instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -9.017003321787342e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 7.632494458675865e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -6.545661079826459e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -9.70192957083782e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 7.444878491469353e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -7.75507515982099e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.3312886792959944e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.1724716308947336e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.3119730302157961e-10 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/data/proj/voice/pyvoice_venv/lib/python3.10/site-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.0000000116860974e-07 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ReDimNet_no_mel.onnx to half precision and saved as ReDimNet_no_mel_fp16.onnx\n"
     ]
    }
   ],
   "source": [
    "myUtils.restore_in_half_precision('ReDimNet_no_mel.onnx','ReDimNet_no_mel_fp16.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = \"ReDimNet_no_mel.onnx\"\n",
    "# onnx_model_path = \"ReDimNet_no_mel_fp16.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_onnx(wav_path):\n",
    "    \"\"\"\n",
    "    Loads an audio file, converts to log-mel, and runs inference\n",
    "    in an ONNX session. Returns the embedding as a NumPy array.\n",
    "    \"\"\"\n",
    "    print(\"===================================================\")\n",
    "    print(\"===========   run_inference_onnx   ================\")\n",
    "    print(\"===================================================\")\n",
    "    #######################################\n",
    "    # 1) Load your ONNX model\n",
    "    #######################################\n",
    "    # (Optional) onnx.checker to confirm its valid\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(f\"Loaded and checked ONNX model from: {onnx_path}\")\n",
    "\n",
    "    # Create an inference session\n",
    "    session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "    # Usually we retrieve the first input & output name\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "    #######################################\n",
    "    # 2) Load audio, get log-mel\n",
    "    #######################################\n",
    "    print(\"loading audio from:\", wav_path)\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    print(f\"...Waveform rate {sample_rate}  ; shape : {waveform.shape}\")\n",
    "\n",
    "    \n",
    "    # If multi-channel, downmix:\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        \n",
    "    # Resample if needed\n",
    "    target_sample_rate=16000\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "        # save resampled waveform to files with suffix \"_resampled_16.wav\"\n",
    "        # torchaudio.save(wav_path.replace(\".wav\", \"_resampled_16.wav\"), waveform, target_sample_rate)\n",
    "\n",
    "    log_mel = myUtils.waveform_to_logmel(waveform)\n",
    "\n",
    "    #######################################\n",
    "    # 3) ONNX Inference\n",
    "    #######################################\n",
    "    # Convert to NumPy for ONNX runtime\n",
    "    log_mel_np = log_mel.cpu().numpy()\n",
    "    \n",
    "    ## save log_mel_np to file with suffix \"_logmel.npy\" to check later\n",
    "    print(\"logmelshape : \", log_mel_np.shape)\n",
    "    log_mel_fp16 = log_mel_np.astype(np.float16)  #  half precision\n",
    "    np.save(wav_path.replace(\".wav\", \"_logmel.npy\"), log_mel_fp16 )\n",
    "    \n",
    "    # Run inference\n",
    "    outputs = session.run([output_name], {input_name: log_mel_np})\n",
    "    # outputs is a list; typically we want the first item\n",
    "    embedding = outputs[0]  # shape is [1, embedding_dim]\n",
    "\n",
    "    # print(\"Embedding[10]: \", embedding[0:10])  # Print the 10th element of the embedding\n",
    "    print(\"Embedding shape:\", embedding.shape)\n",
    "    # print(\"Embedding data:\\n\", embedding)\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB2/utils/../audio/test000.wav\n",
      "...Waveform rate 16000  ; shape : torch.Size([1, 293699])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 72, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB2/utils/../audio/testRob1.wav\n",
      "...Waveform rate 22050  ; shape : torch.Size([1, 35522])\n",
      "Input waveform shape: torch.Size([1, 25776])\n",
      "Padding log_mel from 108 to 134 frames\n",
      "logmelshape :  (1, 1, 72, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB2/utils/../audio/testRob2.wav\n",
      "...Waveform rate 22050  ; shape : torch.Size([1, 32482])\n",
      "Input waveform shape: torch.Size([1, 23570])\n",
      "Padding log_mel from 99 to 134 frames\n",
      "logmelshape :  (1, 1, 72, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB2/utils/../audio/test_human1_1.wav\n",
      "...Waveform rate 16000  ; shape : torch.Size([1, 65867])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 72, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB2/utils/../audio/test_human1_2.wav\n",
      "...Waveform rate 16000  ; shape : torch.Size([1, 101189])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 72, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB2/utils/../audio/test_human2_1.wav\n",
      "...Waveform rate 48000  ; shape : torch.Size([1, 84376])\n",
      "Input waveform shape: torch.Size([1, 28126])\n",
      "Padding log_mel from 118 to 134 frames\n",
      "logmelshape :  (1, 1, 72, 134)\n",
      "Embedding shape: (1, 192)\n",
      "===================================================\n",
      "===========   run_inference_onnx   ================\n",
      "===================================================\n",
      "Loaded and checked ONNX model from: ReDimNet_no_mel.onnx\n",
      "loading audio from: /data/proj/voice/redimnet/wrkB2/utils/../audio/test_human2_2.wav\n",
      "...Waveform rate 48000  ; shape : torch.Size([1, 159256])\n",
      "Input waveform shape: torch.Size([1, 32000])\n",
      "logmelshape :  (1, 1, 72, 134)\n",
      "Embedding shape: (1, 192)\n",
      "**************************************************************************\n",
      "*************************   compare summary ******************************\n",
      "**************************************************************************\n",
      "====>>>> should be similar:\n",
      "Similarity (robot1 to robot2 ): 0.669571042060852\n",
      "Similarity (human1 to human1 ): 0.5778867602348328\n",
      "Similarity (human2 to human2 ): 0.39133644104003906\n",
      "====>>>> should be differnet:\n",
      "Similarity (robot to human1  ): 0.03835272416472435\n",
      "Similarity (robot to human2  ): -0.07448556274175644\n",
      "Similarity (human1 to human2 ): 0.04683849215507507\n"
     ]
    }
   ],
   "source": [
    "onnx_embedding = test_all_voices(\n",
    "    extract_speaker_embedding_function = inference_onnx,\n",
    "    cosine_similarity_function = myUtils.cosine_similarity_numpys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare onnx with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity embde0: 0.9999999403953552\n",
      "Similarity embde1: 1.0000001192092896\n",
      "Similarity embde2: 1.0\n",
      "Similarity embde3: 1.0000001192092896\n",
      "Similarity embde4: 1.0000001192092896\n",
      "Similarity embde5: 0.9999998807907104\n",
      "Similarity embde6: 0.9999999403953552\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity embde0: {myUtils.cosine_similarity_numpys(torch_embedding['embed0'], onnx_embedding['embed0'])}\")\n",
    "print(f\"Similarity embde1: {myUtils.cosine_similarity_numpys(torch_embedding['embed1'], onnx_embedding['embed1'])}\")\n",
    "print(f\"Similarity embde2: {myUtils.cosine_similarity_numpys(torch_embedding['embed2'], onnx_embedding['embed2'])}\")\n",
    "print(f\"Similarity embde3: {myUtils.cosine_similarity_numpys(torch_embedding['embed3'], onnx_embedding['embed3'])}\")\n",
    "print(f\"Similarity embde4: {myUtils.cosine_similarity_numpys(torch_embedding['embed4'], onnx_embedding['embed4'])}\")\n",
    "print(f\"Similarity embde5: {myUtils.cosine_similarity_numpys(torch_embedding['embed5'], onnx_embedding['embed5'])}\")\n",
    "print(f\"Similarity embde6: {myUtils.cosine_similarity_numpys(torch_embedding['embed6'], onnx_embedding['embed6'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare onnx with base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity embde0: 0.9999999403953552\n",
      "Similarity embde1: 0.9944315552711487\n",
      "Similarity embde2: 0.9896696209907532\n",
      "Similarity embde3: 0.9992930293083191\n",
      "Similarity embde4: 0.9998515844345093\n",
      "Similarity embde5: 0.997683584690094\n",
      "Similarity embde6: 0.9999997615814209\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity embde0: {myUtils.cosine_similarity_numpys(base_line_embedding['embed0'], onnx_embedding['embed0'])}\")\n",
    "print(f\"Similarity embde1: {myUtils.cosine_similarity_numpys(base_line_embedding['embed1'], onnx_embedding['embed1'])}\")\n",
    "print(f\"Similarity embde2: {myUtils.cosine_similarity_numpys(base_line_embedding['embed2'], onnx_embedding['embed2'])}\")\n",
    "print(f\"Similarity embde3: {myUtils.cosine_similarity_numpys(base_line_embedding['embed3'], onnx_embedding['embed3'])}\")\n",
    "print(f\"Similarity embde4: {myUtils.cosine_similarity_numpys(base_line_embedding['embed4'], onnx_embedding['embed4'])}\")\n",
    "print(f\"Similarity embde5: {myUtils.cosine_similarity_numpys(base_line_embedding['embed5'], onnx_embedding['embed5'])}\")\n",
    "print(f\"Similarity embde6: {myUtils.cosine_similarity_numpys(base_line_embedding['embed6'], onnx_embedding['embed6'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvoice_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
